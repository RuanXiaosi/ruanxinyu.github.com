[{"title":"AngularJS学习记录-1","date":"2018-10-07T03:50:16.000Z","path":"posts/AngularJS学习记录-1/","text":"前言AngularJS的学习地址为：https://angular.cns/guide/quickstart ng命令介绍 安装@angular/cli: npm install -g @angular/cli 创建工程： ng new angular-tour-of-heroes 开启调试： ng serve --open 创建组件： ng generate component xxx 创建服务： ng generate service xxx 创建路由：ng generate module xxx --flat --module=app 创建类：ng generate class hero 核心知识架构Angular 的基本构造块是 NgModule，它为组件提供了编译的上下文环境。Angular包含一个根模块，可以包含其他模块，模块的加载是懒加载的。 组件定义视图，同时使用服务。组件和服务都是简单的类，这些类使用装饰器来标出它们的类型，并提供元数据以告知 Angular 该如何使用它们。 模板会把 HTML 和 Angular 的标记（markup）组合起来，这些标记可以在 HTML 元素显示出来之前修改它们。 模板中的指令会提供程序逻辑，而绑定标记会把你应用中的数据和 DOM 连接在一起。包含事件绑定和属性绑定，并且支持双星绑定和管道等功能。 对于与特定视图无关并希望跨组件共享的数据或逻辑，可以创建服务类。 服务类的定义通常紧跟在 “@Injectable” 装饰器之后。该装饰器提供的元数据可以让你的服务作为依赖被注入到客户组件中。 Angular 的 Router 模块提供了一个服务，它可以让你定义在应用的各个不同状态和视图层次结构之间导航时要使用的路径。如果路由器认为当前的应用状态需要某些特定的功能，而定义此功能的模块尚未加载，路由器就会按需惰性加载此模块。 模块NgModule 是一个带有 @NgModule 装饰器的类。@NgModule 装饰器是一个函数，它接受一个元数据对象，该对象的属性用来描述这个模块。其中最重要的属性如下。 declarations（可声明对象表） —— 那些属于本 NgModule 的组件、指令、管道。 exports（导出表） —— 那些能在其它模块的组件模板中使用的可声明对象的子集。 imports（导入表） —— 那些导出了本模块中的组件模板所需的类的其它模块。 providers —— 本模块向全局服务中贡献的那些服务的创建器。 这些服务能被本应用中的任何部分使用。（你也可以在组件级别指定服务提供商，这通常是首选方式。） bootstrap —— 应用的主视图，称为根组件。它是应用中所有其它视图的宿主。只有根模块才应该设置这个 bootstrap 属性。 12345678910import &#123; NgModule &#125; from '@angular/core';import &#123; BrowserModule &#125; from '@angular/platform-browser';@NgModule(&#123; imports: [ BrowserModule ], providers: [ Logger ], declarations: [ AppComponent ], exports: [ AppComponent ], bootstrap: [ AppComponent ]&#125;)export class AppModule &#123; &#125; 组件组件通过constructor来提供依赖注入，常见的元数据如下： selector：是一个 CSS 选择器，它会告诉 Angular，一旦在模板 HTML 中找到了这个选择器对应的标签，就创建并插入该组件的一个实例。 templateUrl：该组件的 HTML 模板文件相对于这个组件文件的地址。 providers: 是当前组件所需的依赖注入提供商的一个数组 1234567@Component(&#123; selector: 'app-hero-list', templateUrl: './hero-list.component.html', providers: [ HeroService ]&#125;)export class HeroListComponent implements OnInit &#123;&#125; 指令：结构型指令和属性型指令。 服务与依赖注入服务是一个广义的概念，它包括应用所需的任何值、函数或特性。狭义的服务是一个明确定义了用途的类。它应该做一些具体的事，并做好。要把一个类定义为服务，就要用 @Injectable 装饰器来提供元数据，以便让 Angular 可以把它作为依赖注入到组件中。通过构造函数进行注入 Angular 把组件和服务区分开，以提高模块性和复用性。 通过把组件中和视图有关的功能与其他类型的处理分离开，你可以让组件类更加精简、高效。 理想情况下，组件的工作只管用户体验，而不用顾及其它。 它应该提供用于数据绑定的属性和方法，以便作为视图（由模板渲染）和应用逻辑（通常包含一些模型的概念）的中介者。 组件不应该定义任何诸如从服务器获取数据、验证用户输入或直接往控制台中写日志等工作。 而要把这些任务委托给各种服务。通过把各种处理任务定义到可注入的服务类中，你可以让它被任何组件使用。 通过在不同的环境中注入同一种服务的不同提供商，你还可以让你的应用更具适应性。 默认情况下，Angular CLI 的 ng generate service 命令会在 @Injectable 装饰器中提供元数据，把它注册到根注入器中。本教程就用这种方法注册了 HeroService 的提供商 当你使用特定的 NgModule 注册提供商时，该服务的同一个实例将会对该 NgModule 中的所有组件可用。要想在这一层注册，请用 @NgModule 装饰器中的 providers 属性 当你在组件级注册提供商时，你会为该组件的每一个新实例提供该服务的一个新实例。 要在组件级注册，就要在 @Component 元数据的 providers 属性中注册服务提供商 组件与模板显示数据你可以在两种地方存放组件模板。 你可以使用 template 属性把它定义为内联的，或者把模板定义在一个独立的 HTML 文件中， 再通过 @Component 装饰器中的 templateUrl 属性， 在组件元数据中把它链接到组件。 默认情况下，Angular CLI 生成组件时会带有模板文件，你可以通过参数覆盖它：ng generate component hero -it 显示属性。 *ngFor 是 Angular 的“迭代”指令 *ngIf 指令会根据一个布尔条件来显示或移除一个元素 模板语法JavaScript 中那些具有或可能引发副作用的表达式是被禁止的，包括： 赋值 (=, +=, -=, ...) new 运算符 使用 ; 或 , 的链式表达式 自增和自减运算符：++ 和-- 和 JavaScript 语 法的其它显著不同包括： 不支持位运算 | 和 &amp; 具有新的模板表达式运算符，比如 |、?. 和 !。 表达式中的上下文变量是由模板变量、指令的上下文变量（如果有）和组件的成员叠加而成的。 如果你要引用的变量名存在于一个以上的命名空间中，那么，模板变量是最优先的，其次是指令的上下文变量，最后是组件的成员。 模板表达式不能引用全局命名空间中的任何东西，比如 window 或 document。它们也不能调用 console.log 或 Math.max。 它们只能引用表达式上下文中的成员。 模板表达式能成就或毁掉一个应用。请遵循下列指南：没有可见的副作用,执行迅速,非常简单,幂等性 模板语句用来响应由绑定目标（如 HTML 元素、组件或指令）触发的事件。 模板语句将在事件绑定一节看到，它出现在 = 号右侧的引号中，就像这样：(event)=”statement”。 绑定方式： 属性绑定：[target]=&quot;expression&quot; 事件绑定：(target)=&quot;statement&quot; 双向绑定：[(target)]=&quot;expression&quot; css类绑定：[class.special]=&quot;isSpecial&quot; 样式绑定：[style.color]=&quot;isSpecial ? &#39;red&#39; : &#39;green&#39;&quot; 在多数情况下，插值表达式是更方便的备选项。 实际上，在渲染视图之前，Angular 把这些插值表达式翻译成相应的属性绑定。 在新版的 Angular 中不需要那么多指令。 使用更强大、更富有表现力的 Angular 绑定系统，其实可以达到同样的效果。 外部组件应该只能绑定到组件的公共（允许绑定） API 上，Angular 要求你显式声明那些 API。 它让你可以自己决定哪些属性是可以被外部组件绑定的。进行数据绑定的属性都带有 @Input() 和 @Output() 装饰器。 好东西: Angular 的安全导航操作符?. 是一种流畅而便利的方式，用来保护出现在属性路径中 null 和 undefined 值。 下例中，当 currentHero 为空时，保护视图渲染器，让它免于失败。 非空断言操作符! 类型转换函数 $any 生命钩子执行顺序 组件交互https://angular.cn/guide/component-interaction 通过输入型绑定把数据从父组件传到子组件 通过 setter 截听输入属性值的变化 通过ngOnChanges()来截听输入属性值的变化 父组件监听子组件的事件 父组件与子组件通过本地变量互动 父组件调用@ViewChild() 父组件和子组件通过服务来通讯 组件样式 使用 :host 伪类选择器，用来选择组件宿主元素中的元素 使用 :host-context() 伪类选择器。它也以类似 :host() 形式使用。它在当前组件宿主元素的祖先节点中查找 CSS 类， 直到文档的根节点为止 可以在组件的 HTML 模板中写 &lt;link&gt; 标签 可以利用标准的 CSS @import 规则来把其它 CSS 文件导入到 CSS 文件中。 如果使用 CLI 进行构建，那么你可以用 sass、less 或 stylus 来编写样式，并使用相应的扩展名（.scss、.less、.styl）把它们指定到 @Component.styleUrls 元数据中。 表单用户输入https://angular.cn/guide/user-input 绑定到用户输入事件&lt;button (click)=&quot;onClickMe()&quot;&gt;Click me!&lt;/button&gt; 通过 $event 对象取得用户输入&lt;input (keyup)=&quot;onKey($event)&quot;&gt; 从一个模板引用变量中获得用户输入,在标识符前加上井号 (#) 就能声明一个模板引用变量，&lt;input #box (keyup)=&quot;0&quot;&gt; &lt;p&gt;&lt;/p&gt; 按键事件过滤（通过 key.enter）: &lt;input #box (keyup.enter)=&quot;onEnter(box.value)&quot;&gt; &lt;p&gt;&lt;/p&gt;","tags":[{"name":"学习记录","slug":"学习记录","permalink":"http://ruanxinyu.github.io/tags/学习记录/"}]},{"title":"基于SpringBoot+Mybatis开发Restful接口实现数据表的增删改查功能","date":"2018-10-06T07:29:04.000Z","path":"posts/基于SpringBoot+Mybatis开发Restful接口实现数据表的增删改查功能/","text":"基础环境说明本教程使用Maven管理依赖，使用IDEA进行开发，在开始之前，请按照下面教程安装好JDK和Mysql: JDK的安装请参考：JDK安装教程 Mysql的安装请参考： Ubuntu下Mysql的安装与验证 本教程的代码地址为：https://github.com/RuanXinyu/springcloud-demo/tree/master/productionservice 初始化数据库首先创建一个数据库和一个用户，并分配相应的权限： 1234567-- 创建数据库create database mall;-- 创建用户并分配权限，8.0版本需要采用该方式create user malluser@'%' identified by 'mall@123';grant all privileges on mall.* to 'malluser'@'%' with grant option;flush privileges; 然后在mall数据库中创建一张表： 1234567CREATE TABLE `mall`.`t_production` ( `uuid` CHAR(32) NOT NULL, `name` VARCHAR(128) NOT NULL, `price` DECIMAL(12) NOT NULL, `description` VARCHAR(4094) NULL, `create_time` DATETIME NOT NULL, PRIMARY KEY (`uuid`)); 通过IDEA生成基础代码选择Spring Initializr来创建工程： 指定maven的GAV参数，我们组件名称叫productionservice，同时选择jar包启动的方式： Spring组件我们仅选择Web下的Web，SQL下的MySQL和Mybatis: 最后生成的代码目录结构如下： 使用MybatisGenerator生成代码pom.xml首先在pom文件中增加mybatis-generator-maven-plugin插件，如下所示: 12345678910&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator/mybatis_generator.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt;&lt;/plugin&gt; mybatis_generator.xml在src/main/resources/目录下创建generator文件夹，并创建mybatis_generator.xml文件 写入如下的内容： 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;!-- 数据库驱动:选择你的本地硬盘上面的数据库驱动包--&gt; &lt;classPathEntry location=\"D:\\.m2\\mysql\\mysql-connector-java\\5.1.47\\mysql-connector-java-5.1.47.jar\"/&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接URL，用户名、密码 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://127.0.0.1/mall\" userId=\"malluser\" password=\"mall@123\"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- 生成模型的包名和位置--&gt; &lt;javaModelGenerator targetPackage=\"com.ruan.productionservice.model\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成映射文件的包名和位置--&gt; &lt;sqlMapGenerator targetPackage=\"com.ruan.productionservice.mapper\" targetProject=\"src/main/resources\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 生成DAO的包名和位置--&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.ruan.productionservice.mapper\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要生成的表 tableName是数据库中的表名或视图名 domainObjectName是实体类名--&gt; &lt;table tableName=\"t_production\" domainObjectName=\"Production\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"/&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 做几点说明： &lt;classPathEntry location=&quot;D:\\.m2\\mysql\\mysql-connector-java\\5.1.47\\mysql-connector-java-5.1.47.jar&quot;/&gt;中的路径可以从maven的缓存目录中找到 &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://127.0.0.1/mall&quot; userId=&quot;malluser&quot; password=&quot;mall@123&quot;&gt;需要正确填写数据库的数据库名称，用户名，密码和表名称 targetPackage=要修改为对应的包路径 &lt;table tableName=&quot;t_production&quot; domainObjectName=&quot;Production&quot;需要正确填写和实体类名 mybatis-generator:generate最后双击右侧maven窗口中的plugins-&gt;mybatis-generator:generate即可生成代码。 注意不要多次生成，否则xml中可能会生成重复的内容，从而造成启动报错，可以删除文件再生成 最终生成的代码结构如下： 添加查询数据列表接口从MybatisGenerator生成的代码中可以看出已经生成了增删改查的接口，我们在此基础之上增加一个查询列表的接口ArrayList&lt;Production&gt; selectAll()。 ProductionMapper.xml在文件中增加一个selectAll对应的查询语句： 12345&lt;select id=\"selectAll\" resultMap=\"BaseResultMap\"&gt; select &lt;include refid=\"Base_Column_List\" /&gt; from t_production&lt;/select&gt; 如下所示： ProductionMapper.java在接口中增加ArrayList&lt;Production&gt; selectAll();接口声明 增加@Mapper注解MybatisGenerator自动生成的接口ProductionMapper接口默认是没有注解的，需要我们手动增加@Mapper注解，否则启动时会报错。 注意： 每次重新生成代码后都需要重新手动修改 增加service层代码在com.ruan.productionservice.service下创建ProductionService接口，在com.ruan.productionservice.service.impl下创建ProductionServiceImpl类实现ProductionService，如下所示： ProductionService.java接口中声明5个接口函数： 1234567public interface ProductionService &#123; int delete(String uuid); int save(Production record); Production get(String uuid); int update(Production record); ArrayList&lt;Production&gt; list();&#125; ProductionServiceImpl.java实现类ProductionServiceImpl需要加@Service注解， 在保存记录的接口中自动生成主键和创建时间 123456789101112131415161718192021222324252627282930313233@Servicepublic class ProductionServiceImpl implements ProductionService &#123; @Autowired ProductionMapper mapper; @Override public int delete(String uuid) &#123; return mapper.deleteByPrimaryKey(uuid); &#125; @Override public int save(Production production) &#123; production.setUuid(UUID.randomUUID().toString().replace(\"-\", \"\").toLowerCase()); production.setCreateTime(new Date()); return mapper.insert(production); &#125; @Override public int update(Production production) &#123; return mapper.updateByPrimaryKeySelective(production); &#125; @Override public Production get(String uuid) &#123; return mapper.selectByPrimaryKey(uuid); &#125; @Override public ArrayList&lt;Production&gt; list() &#123; return mapper.selectAll(); &#125;&#125; 增加controller层代码ProductionController.java在com.ruan.productionservice.controller下创建ProductionController类，在类上指定@RestController注解，然后实现5个Restful接口，代码如下： 12345678910111213141516171819202122232425262728293031323334353637@RestController@RequestMapping(value = \"/mall/production\")public class ProductionController &#123; @Autowired ProductionService productionService; @ResponseBody @RequestMapping(value = \"/save\", method = RequestMethod.POST) public int save(Production production)&#123; return productionService.save(production); &#125; @ResponseBody @RequestMapping(value = \"/update\", method = RequestMethod.POST) public int update(Production production)&#123; return productionService.update(production); &#125; @ResponseBody @RequestMapping(value = \"/delete/&#123;id&#125;\", method = RequestMethod.POST) public int delete(@PathVariable(\"id\") String id)&#123; return productionService.delete(id); &#125; @ResponseBody @RequestMapping(value = \"/get/&#123;id&#125;\", method = RequestMethod.GET) public Production get(@PathVariable(\"id\") String id)&#123; return productionService.get(id); &#125; @ResponseBody @RequestMapping(value = \"/list\", method = RequestMethod.GET) public ArrayList&lt;Production&gt; list()&#123; return productionService.list(); &#125;&#125; 配置application.propertiesapplication.properties中包含应用的配置信息，我们只需要配置JDBC的内容即可，如下所示： 1234spring.datasource.url=jdbc:mysql://localhost:3306/mallspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.username=malluserspring.datasource.password=mall@123 启动应用程序在IDEA中进去到ProductionserviceApplication类中，然后就可以启动程序，如下所示： PostMan验证接口启动后，我们通过PostMan进行接口的验证。 /mall/production/save创建一条数据，返回1，表示插入数据库成功。 /mall/production/list通过list接口可以看到插入的内容，并且可以看到对应数据的uuid，用来调用其他接口 /mall/production/update通过上面获取到的uuid修改数据，如下，返回1表示数据库修改成功。 /mall/production/get/{id}通过上面获取到的uuid获取数据详情，此时uuid是在网址中，发现price已经修改为35。 /mall/production/delete/{id}最后通过delete接口删除数据 可能遇到的问题启动时提示自动加载ProductionMapper失败如果在启动过程中提示No qualifying bean of type &#39;com.ruan.productionservice.mapper.ProductionMapper&#39; available: expected at least 1 bean which qualifies as autowire candidate.，则说明ProductionMapper没有添加@Mapper注解，该文件是Mybatis Generator自动生成的，需要手动添加该注解。 启动时提示Result Maps错误启动报错提示java.lang.IllegalArgumentException: Result Maps collection already contains value for com.ruan.productionservice.mapper.ProductionMapper.BaseResultMap，是因为多次使用Mybatis Generator生成代码，造成ProductionMapper.xml文件中存在重复的内容，删除掉该文件重新生成即可。","tags":[{"name":"Java","slug":"Java","permalink":"http://ruanxinyu.github.io/tags/Java/"}]},{"title":"Mysql常见问题操作指导","date":"2018-10-06T01:39:34.000Z","path":"posts/Mysql常见问题操作指导/","text":"快速查询目录 启动windows如何启动mysql执行net start mysql80（需要用管理员权限启动，否则会报拒绝访问错误），或者通过如下方式： windows下mysq的数据和配置文件存放位置默认是在C:\\ProgramData\\MySQL\\目录下 windows启动mysql报拒绝访问错误使用管理员权限启动即可，net start mysql80 windows下mysql的日志位置在C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data\\下，可以通过C:\\ProgramData\\MySQL\\MySQL Server 8.0\\my.ini看到具体的文件名称： windows下mysql启动失败查看mysql的错误日志发现如下内容TCP/IP, --shared-memory, or --named-pipe should be configured on NT OS。 有两种解决方式，一种是取消注释enable-named-pipe， 二是取消注释shared-memory。这两个参数在my.ini的位置是在一起的，如下所示： 权限如何添加用户权限老版本授权格式：grant 权限 on 数据库.* to 用户名@登录主机 identified by &quot;密码&quot;; 12grant all privileges on mall.* to 'malluser'@'%' identified by 'mall@123';flush privileges; 8.0版本: 创建账户和赋予权限分开，如果采用上面的方式会提示Error Code: 1064. You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;IDENTIFIED BY &#39;mall@1234&#39;&#39;,，因此需要采用下面的方式： 创建账户: create user &#39;用户名&#39;@&#39;访问主机&#39; identified by &#39;密码&#39;; 赋予权限: grant 权限列表 on 数据库 to &#39;用户名&#39;@&#39;访问主机&#39;;（修改权限时在后面加with grant option） 123create user malluser@'%' identified by 'mall@123';grant all privileges on mall.* to 'malluser'@'%' with grant option;flush privileges; 忘记root的密码首先，编辑sudo vim /etc/mysql/my.cnf，在[mysqld]下添加skip-grant-tables，然后重启sudo systemctl restart mysql.service，然后就可以通过mysql -u root进入到mysql的控制台。 执行mysql命令进入到mysql的控制台，执行如下命令修改密码： mysql 5.7.9版本之前 123use mysql;update user set Password = password ( 'new-password' ) where User = 'root';flush privileges; mysql 5.7.9版本之后 1234use mysql;update user set authentication_string='' where user='root';flush privileges;ALTER user 'root'@'localhost' IDENTIFIED BY 'root@123'; 最后，删除skip-grant-tables配置并重启mysql即可完成密码的修改。 修改权限提示–skip-grant-tables下不能执行该操作提示The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement，在执行之前执行一下flush privileges;即可。","tags":[{"name":"飞行手册","slug":"飞行手册","permalink":"http://ruanxinyu.github.io/tags/飞行手册/"}]},{"title":"Ubuntu常见问题操作指导","date":"2018-10-04T13:27:53.000Z","path":"posts/Ubuntu常见问题操作指导/","text":"如何重启网卡重启网卡可以使用ip，ifconfig和service命令，如下所示，推荐使用ip命令。 12345678910# 推荐使用ip命令sudo ip link set enp0s3 downsudo ip link set enp0s3 up# 使用ifconfig命令sudo ifconfig enp0s3 downsudo ifconfig enp0s3 up# 使用service命令，但是不支持最新版的Ubuntusudo service network restart 如何临时添加-修改-删除IP地址可以使用ip和ifconfig命令，如下所示，推荐使用ip命令。 12345678# 推荐使用ip命令sudo ip address add 192.168.1.135/32 dev enp0s3 # 添加sudo ip address change 192.168.1.135/24 dev enp0s3 # 修改sudo ip address del 192.168.1.135/24 dev enp0s3 # 删除# 使用ifconfig命令sudo ifconfig eth0 192.168.1.135 netmask 255.255.255.0 如何设置静态IP地址和DNS 由于Ubuntu从17.10开始改用netplan方式管理，因此在不同版本设置方式不一样。 Ubuntu 17.10版本前，编辑sudo vim /etc/network/interfaces文件，添加如下的内容，然后重启网卡即可。 123456auto enp0s3iface enp0s3 inet staticaddress 192.168.1.132netmask 255.255.255.0gateway 192.168.1.1dns-nameserver 192.168.1.1 Ubuntu 17.10版本后，编辑netplan方式的配置文件sudo vim /etc/netplan/50-cloud-init.yaml，设置如下内容，然后执行sudo netplan apply即可立即生效。 12345678910network: ethernets: enp0s3: # 配置的网卡名称 dhcp4: no # dhcp4关闭 dhcp6: no # dhcp6关闭 addresses: [192.168.1.132/24] # 设置本机IP及掩码 gateway4: 192.168.1.1 # 设置网关 nameservers: addresses: [192.168.1.1] # 设置DNS version: 2 如何查看和设置DNS 修改/etc/resolv.conf文件是无效的，该文件每次重启会被自动覆盖 如果是修改单个网卡的DNS请参见：如何设置静态IP地址和DNS 如果是设置全局DNS，请编辑sudo vim /etc/systemd/resolved.conf，然后重启systemd-resolved服务sudo systemctl restart systemd-resolved.service即可。 查看当前正在使用的DNS可以使用sudo systemd-resolve --status","tags":[{"name":"飞行手册","slug":"飞行手册","permalink":"http://ruanxinyu.github.io/tags/飞行手册/"}]},{"title":"Ubuntu下Mysql的安装与验证","date":"2018-10-04T13:21:18.000Z","path":"posts/Ubuntu下Mysql的安装与验证/","text":"apt方式安装 Ubuntu 18.04.1版本下，如果直接使用sudo apt-get install mysql-server安装的是5.9版本，我们要安装最新的8.0版本。 首先进去到https://dev.mysql.com/downloads/repo/apt/页面，下载deb包 点击下载按钮后，我们也可以页面中获取下载地址，然后通过wget下载： 通过wget下载后通过执行dpkg命令安装deb包，并且在弹出的框中我们选择8.0版本： 12wget https://dev.mysql.com/get/mysql-apt-config_0.8.10-1_all.debsudo dpkg -i mysql-apt-config_0.8.10-1_all.deb # 在弹出的框中我们选择8.0版本 由于安装过程中需要使用到libmecab2包，所以也需要提前安装好，否则会提示Depends: mysql-community-server (= 8.0.12-1ubuntu18.04) but it is not going to be installed。 12wget http://security.ubuntu.com/ubuntu/pool/universe/m/mecab/libmecab2_0.996-5_amd64.debsudo dpkg -i libmecab2_0.996-5_amd64.deb 安装好libmecab2后就可以安装mysql-server了。 12sudo apt-get updatesudo apt-get install mysql-server 安装过程中会提示用户选择密码的加密方式，由于Mysql 8.0开始支持更加安全的基于SHA256的加密方式，但是老的驱动是不支持该加密方式，所以如果已经有其他程序使用该Mysql，需要保持兼容，则选择兼容模式，否则推荐使用最一种模式。 启动与开机启动安装完成后mysql自动已经起来，可以通过systemctl命令启动，停止和查看mysql，并且加入到开机启动。 1234sudo systemctl stop mysql.servicesudo systemctl start mysql.servicesudo systemctl status mysql.servicesudo systemctl enable mysql.service mysql的相关目录及文件位置说明： 用户配置文件位置：/etc/mysql/my.cnf pid文件位置：/var/run/mysqld/mysqld.pid socket文件位置：/var/run/mysqld/mysqld.sock 数据目录： /var/lib/mysql 错误日志文件： /var/log/mysql/error.log 在控制台执行mysql -u root -p，输入密码就可以进入","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"Git常见问题操作指导","date":"2018-10-04T05:15:35.000Z","path":"posts/Git常见问题操作指导/","text":"图形化客户端强烈推荐：SmartGit， 本文是基于Git飞行规则上做的修改与补充。 快速查询目录 为了清楚的表述，这篇文档里的所有例子使用了自定义的bash 提示，以便指示当前分支和是否有暂存的变化(changes)。分支名用小括号括起来，分支名后面跟的*表示暂存的变化(changes)。 编辑提交(editting commits)刚才提交了什么如果你用 git commit -a 提交了一次变化(changes)，而你又不确定到底这次提交了哪些内容。 你就可以用下面的命令显示当前HEAD上的最近一次的提交(commit): 1(master)$ git show 或者 1$ git log -n1 -p 提交信息写错了如果你的提交信息(commit message)写错了且这次提交(commit)还没有推(push), 你可以通过下面的方法来修改提交信息(commit message): 1$ git commit --amend 这会打开你的默认编辑器, 在这里你可以编辑信息. 另一方面, 你也可以用一条命令一次完成: 1$ git commit --amend -m 'xxxxxxx' 如果你已经推(push)了这次提交(commit), 你可以修改这次提交(commit)然后强推(force push), 但是不推荐这么做。 提交里的用户名和邮箱不对如果这只是单个提交(commit)，修改它： 1$ git commit --amend --author \"New Authorname &lt;authoremail@mydomain.com&gt;\" 如果你需要修改所有历史, 参考 ‘git filter-branch’的指南页. 想从一个提交里移除一个文件通过下面的方法，从一个提交(commit)里移除一个文件: 123$ git checkout HEAD^ myfile$ git add -A$ git commit --amend 这将非常有用，当你有一个开放的补丁(open patch)，你往上面提交了一个不必要的文件，你需要强推(force push)去更新这个远程补丁。 想删除最后一次提交如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。 12$ git reset HEAD^ --hard$ git push -f [remote] [branch] 如果你还没有推到远程, 把Git重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化): 1(my-branch*)$ git reset --soft HEAD@&#123;1&#125; 这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 git revert SHAofBadCommit， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是rebase-safe的 (例如： 其它开发者不会从这个分支拉), 只需要使用 git push -f； 更多, 请参考 the above section。 删除任意提交同样的警告：不到万不得已的时候不要这么做. 12$ git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT$ git push -f [remote] [branch] 或者做一个 交互式rebase 删除那些你想要删除的提交(commit)里所对应的行。 尝试推一个修正后的提交到远程，但是报错：1234567To https://github.com/yourusername/repo.git! [rejected] mybranch -&gt; mybranch (non-fast-forward)error: failed to push some refs to 'https://github.com/tanay1337/webmaker.org.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 注意, rebasing(见下面)和修正(amending)会用一个新的提交(commit)代替旧的, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (-f)。 注意 &ndash; 总是 确保你指明一个分支! 1(my-branch)$ git push origin mybranch -f 一般来说, 要避免强推. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。 意外的做了一次硬重置，想找回内容如果你意外的做了 git reset --hard, 你通常能找回你的提交(commit), 因为Git对每件事都会有日志，且都会保存几天。 1(master)$ git reflog 你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的SHA，再重置一次: 1(master)$ git reset --hard SHA1234 这样就完成了。 暂存(Staging)需要把暂存的内容添加到上一次的提交1(my-branch*)$ git commit --amend 想要暂存一个新文件的一部分，而不是这个文件的全部一般来说, 如果你想暂存一个文件的一部分, 你可这样做: 1$ git add --patch filename.x -p 简写。这会打开交互模式， 你将能够用 s 选项来分隔提交(commit)； 然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时, 这样做: 1$ git add -N filename.x 然后, 你需要用 e 选项来手动选择需要添加的行，执行 git diff --cached 将会显示哪些行暂存了哪些行只是保存在本地了。 想把在一个文件里的变化加到两个提交里git add 会把整个文件加入到一个提交. git add -p 允许交互式的选择你想要提交的部分. 想把暂存的内容变成未暂存，把未暂存的内容暂存起来这个有点困难， 我能想到的最好的方法是先stash未暂存的内容， 然后重置(reset)，再pop第一步stashed的内容, 最后再add它们。 1234$ git stash -k$ git reset --hard$ git stash pop$ git add -A 未暂存(Unstaged)的内容想把未暂存的内容移动到一个新分支1$ git checkout -b my-branch 想把未暂存的内容移动到另一个已存在的分支123$ git stash$ git checkout my-branch$ git stash pop 想丢弃本地未提交的变化如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以： 12345678# one commit(my-branch)$ git reset --hard HEAD^# two commits(my-branch)$ git reset --hard HEAD^^# four commits(my-branch)$ git reset --hard HEAD~4# or(master)$ git checkout -f 重置某个特殊的文件, 你可以用文件名做为参数: 1$ git reset filename 想丢弃某些未暂存的内容如果你想丢弃工作拷贝中的一部分内容，而不是全部。 签出(checkout)不需要的内容，保留需要的。 12$ git checkout -p# Answer y to all of the snippets you want to drop 另外一个方法是使用 stash， Stash所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。 1234$ git stash -p# Select all of the snippets you want to save$ git reset --hard$ git stash pop 或者, stash 你不需要的部分, 然后stash drop。 123$ git stash -p# Select all of the snippets you don't want to save$ git stash drop 分支(Branches)从错误的分支拉取了内容，或把内容拉取到了错误的分支这是另外一种使用 git reflog 情况，找到在这次错误拉(pull) 之前HEAD的指向。 123(master)$ git reflogab7555f HEAD@&#123;0&#125;: pull origin wrong-branch: Fast-forwardc5bc55a HEAD@&#123;1&#125;: checkout: checkout message goes here 重置分支到你所需的提交(desired commit): 1$ git reset --hard c5bc55a 完成。 想扔掉本地的提交，以便我的分支与远程的保持一致先确认你没有推(push)你的内容到远程。 git status 会显示你领先(ahead)源(origin)多少个提交: 12345(my-branch)$ git status# On branch my-branch# Your branch is ahead of 'origin/my-branch' by 2 commits.# (use \"git push\" to publish your local commits)# 一种方法是: 1(master)$ git reset --hard origin/my-branch 需要提交到一个新分支，但错误的提交到了master在master下创建一个新分支，不切换到新分支,仍在master下: 1(master)$ git branch my-branch 把master分支重置到前一个提交: 1(master)$ git reset --hard HEAD^ HEAD^ 是 HEAD^1 的简写，你可以通过指定要设置的HEAD来进一步重置。 或者, 如果你不想使用 HEAD^, 找到你想重置到的提交(commit)的hash(git log 能够完成)， 然后重置到这个hash。 使用git push 同步内容到远程。 例如, master分支想重置到的提交的hash为a13b85e: 12(master)$ git reset --hard a13b85eHEAD is now at a13b85e 签出(checkout)刚才新建的分支继续工作: 1(master)$ git checkout my-branch 想保留来自另外一个ref-ish的整个文件假设你正在做一个原型方案(原文为working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容: 1(solution)$ git add -A &amp;&amp; git commit -m \"Adding all changes from this spike into one big commit.\" 当你想要把它放到一个分支里 (可能是feature, 或者 develop), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。 假设你有: 分支 solution, 拥有原型方案， 领先 develop 分支。 分支 develop, 在这里你应用原型方案的一些内容。 我去可以通过把内容拿到你的分支里，来解决这个问题: 1(develop)$ git checkout solution -- file1.txt 这会把这个文件内容从分支 solution 拿到分支 develop 里来: 123456# On branch develop# Your branch is up-to-date with 'origin/develop'.# Changes to be committed:# (use \"git reset HEAD &lt;file&gt;...\" to unstage)## modified: file1.txt 然后, 正常提交。 Note: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ Wikipedia. 把几个提交提交到了同一个分支，而这些提交应该分布在不同的分支里假设你有一个master分支， 执行git log, 你看到你做过两次提交: 12345678910111213141516171819(master)$ git logcommit e3851e817c451cc36f2e6f3049db528415e3c114Author: Alex Lee &lt;alexlee@example.com&gt;Date: Tue Jul 22 15:39:27 2014 -0400 Bug #21 - Added CSRF protectioncommit 5ea51731d150f7ddc4a365437931cd8be3bf3131Author: Alex Lee &lt;alexlee@example.com&gt;Date: Tue Jul 22 15:39:12 2014 -0400 Bug #14 - Fixed spacing on titlecommit a13b85e984171c6e2a1729bb061994525f626d14Author: Aki Rose &lt;akirose@example.com&gt;Date: Tue Jul 21 01:12:48 2014 -0400 First commit 让我们用提交hash(commit hash)标记bug (e3851e8 for #21, 5ea5173 for #14). 首先, 我们把master分支重置到正确的提交(a13b85e): 12(master)$ git reset --hard a13b85eHEAD is now at a13b85e 现在, 我们对 bug #21 创建一个新的分支: 12(master)$ git checkout -b 21(21)$ 接着, 我们用 cherry-pick 把对bug #21的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在HEAD上面。 1(21)$ git cherry-pick e3851e8 这时候, 这里可能会产生冲突， 参见交互式 rebasing 章 冲突节 解决冲突. 再者， 我们为bug #14 创建一个新的分支, 也基于master分支 123(21)$ git checkout master(master)$ git checkout -b 14(14)$ 最后, 为 bug #14 执行 cherry-pick: 1(14)$ git cherry-pick 5ea5173 想删除上游分支被删除了的本地分支一旦你在github 上面合并(merge)了一个pull request, 你就可以删除你fork里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。 1$ git fetch -p 不小心删除了我的分支如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件: 12345(master)$ git checkout -b my-branch(my-branch)$ git branch(my-branch)$ touch foo.txt(my-branch)$ lsREADME.md foo.txt 添加文件并做一次提交 123456789101112131415161718(my-branch)$ git add .(my-branch)$ git commit -m 'foo.txt added'(my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt(my-branch)$ git logcommit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012Author: siemiatj &lt;siemiatj@example.com&gt;Date: Wed Jul 30 00:34:10 2014 +0200 foo.txt addedcommit 69204cdf0acbab201619d95ad8295928e7f411d5Author: Kate Hudson &lt;katehudson@example.com&gt;Date: Tue Jul 29 13:14:46 2014 -0400 Fixes #6: Force pushing after amending commits 现在我们切回到主(master)分支，‘不小心的’删除my-branch分支 1234567(my-branch)$ git checkout masterSwitched to branch 'master'Your branch is up-to-date with 'origin/master'.(master)$ git branch -D my-branchDeleted branch my-branch (was 4e3cd85).(master)$ echo oh noes, deleted my branch!oh noes, deleted my branch! 在这时候你应该想起了reflog, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。 1234(master)$ git reflog69204cd HEAD@&#123;0&#125;: checkout: moving from my-branch to master4e3cd85 HEAD@&#123;1&#125;: commit: foo.txt added69204cd HEAD@&#123;2&#125;: checkout: moving from master to my-branch 正如你所见，我们有一个来自删除分支的提交hash(commit hash)，接下来看看是否能恢复删除了的分支。 123456(master)$ git checkout -b my-branch-helpSwitched to a new branch 'my-branch-help'(my-branch-help)$ git reset --hard 4e3cd85HEAD is now at 4e3cd85 foo.txt added(my-branch-help)$ lsREADME.md foo.txt 看! 我们把删除的文件找回来了。 Git的 reflog 在rebasing出错的时候也是同样有用的。 想删除一个分支删除一个远程分支: 1(master)$ git push origin --delete my-branch 你也可以: 1(master)$ git push origin :my-branch 删除一个本地分支: 1(master)$ git branch -D my-branch 想从别人正在工作的远程分支签出一个分支首先, 从远程拉取(fetch) 所有分支: 1(master)$ git fetch --all 假设你想要从远程的daves分支签出到本地的daves 123(master)$ git checkout --track origin/davesBranch daves set up to track remote branch daves from origin.Switched to a new branch 'daves' (--track 是 git checkout -b [branch] [remotename]/[branch] 的简写) 这样就得到了一个daves分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到. Rebasing 和合并(Merging)想撤销rebase/merge你可以合并(merge)或rebase了一个错误的分支, 或者完成不了一个进行中的rebase/merge。 Git 在进行危险操作的时候会把原始的HEAD保存在一个叫ORIG_HEAD的变量里, 所以要把分支恢复到rebase/merge前的状态是很容易的。 1(my-branch)$ git reset --hard ORIG_HEAD 已经rebase过, 但是我不想强推不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了Git历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做: 1234(master)$ git checkout my-branch(my-branch)$ git rebase -i master(my-branch)$ git checkout master(master)$ git merge --ff-only my-branch 更多, 参见 this SO thread. 需要组合几个提交假设你的工作分支将会做对于 master 的pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 所有 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(master)分支是最新的和你的变化都已经提交了, 然后: 12(my-branch)$ git reset --soft master(my-branch)$ git commit -am \"New awesome feature\" 如果你想要更多的控制, 想要保留时间戳, 你需要做交互式rebase (interactive rebase): 1(my-branch)$ git rebase -i master 如果没有相对的其它分支， 你将不得不相对自己的HEAD 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于HEAD~2 进行rebase， 组合最近3次提交(commit), 相对于HEAD~3, 等等。 1(master)$ git rebase -i HEAD~2 在你执行了交互式 rebase的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容: 12345678910111213141516171819202122pick a9c8a1d Some refactoringpick 01b2fd8 New awesome featurepick b729ad5 fixuppick e3851e8 another fix# Rebase 8074d12..b729ad5 onto 8074d12## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like \"squash\", but discard this commit's log message# x, exec = run command (the rest of the line) using shell## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 所有以 # 开头的行都是注释, 不会影响 rebase. 然后，你可以用任何上面命令列表的命令替换 pick, 你也可以通过删除对应的行来删除一个提交(commit)。 例如, 如果你想 单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 f: 1234pick a9c8a1d Some refactoringpick 01b2fd8 New awesome featuref b729ad5 fixupf e3851e8 another fix 如果你想组合这些提交(commit) 并重命名这个提交(commit), 你应该在第二个提交(commit)旁边添加一个r，或者更简单的用s 替代 f: 1234pick a9c8a1d Some refactoringpick 01b2fd8 New awesome features b729ad5 fixups e3851e8 another fix 你可以在接下来弹出的文本提示框里重命名提交(commit)。 12345678910Newer, awesomer features# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.# rebase in progress; onto 8074d12# You are currently editing a commit while rebasing branch 'master' on '8074d12'.## Changes to be committed:# modified: README.md# 如果成功了, 你应该看到类似下面的内容: 1(master)$ Successfully rebased and updated refs/heads/master. 安全合并策略--no-commit 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 no-ff 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。 1(master)$ git merge --no-ff --no-commit my-branch 需要将一个分支合并成一个提交1(master)$ git merge --squash my-branch 只想组合未推的提交有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。 1(master)$ git rebase -i @&#123;u&#125; 这会产生一次交互式的rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行reorder/fix/squash 都是安全的。 检查是否分支上的所有提交都合并过了检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的head(或任何 commits)之间做一次diff: 1(master)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll 这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是: 1(master)$ git log master ^feature/120-on-scroll --no-merges 交互式rebase可能出现的问题这个rebase编辑屏幕出现’noop’如果你看到的是这样:1noop 这意味着你rebase的分支和当前分支在同一个提交(commit)上, 或者 领先(ahead) 当前分支。 你可以尝试: 检查确保主(master)分支没有问题 rebase HEAD~2 或者更早 有冲突的情况如果你不能成功的完成rebase, 你可能必须要解决冲突。 首先执行 git status 找出哪些文件有冲突: 1234567(my-branch)$ git statusOn branch my-branchChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)truemodified: README.md 在这个例子里面, README.md 有冲突。 打开这个文件找到类似下面的内容: 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADsome code=========some code&gt;&gt;&gt;&gt;&gt;&gt;&gt; new-commit 你需要解决新提交的代码(示例里, 从中间==线到new-commit的地方)与HEAD 之间不一样的地方. 有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor): 1(master*)$ git mergetool -t opendiff 在你解决完所有冲突和测试过后, git add 变化了的(changed)文件, 然后用git rebase --continue 继续rebase。 12(my-branch)$ git add README.md(my-branch)$ git rebase --continue 如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行git rebase --skip。 任何时候你想结束整个rebase 过程，回来rebase前的分支状态, 你可以做: 1(my-branch)$ git rebase --abort 杂项(Miscellaneous Objects)克隆所有子模块1$ git clone --recursive git://github.com/foo/bar.git 如果已经克隆了: 1$ git submodule update --init --recursive 删除标签12$ git tag -d &lt;tag_name&gt;$ git push &lt;remote&gt; :refs/tags/&lt;tag_name&gt; 恢复已删除标签如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag): 1$ git fsck --unreachable | grep tag 记下这个标签(tag)的hash，然后用Git的 update-ref: 1$ git update-ref refs/tags/&lt;tag_name&gt; &lt;hash&gt; 这时你的标签(tag)应该已经恢复了。 已删除补丁如果某人在 GitHub 上给你发了一个pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 git am。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。 做完提交后, 再修改作者，参见变更作者。 然后, 应用变化, 再发起一个新的pull request。 跟踪文件(Tracking Files)只想改变一个文件名字的大小写，而不修改内容1(master)$ git mv --force myfile MyFile 想从Git删除一个文件，但保留该文件1(master)$ git rm --cached log.txt 配置(Configuration)想给一些Git命令添加别名在 OS X 和 Linux 下, 你的 Git的配置文件储存在 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下:12345678910111213141516171819202122```vim[alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @&#123;u&#125; s = status unpushed = log @&#123;u&#125; wc = whatchanged wip = rebase -i @&#123;u&#125; zap = fetch -p 想缓存一个仓库的用户名和密码你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper能帮你。 12$ git config --global credential.helper cache# Set git to use the credential memory cache 12$ git config --global credential.helper 'cache --timeout=3600'# Set the cache to timeout after 1 hour (setting is in seconds) 不知道我做错了些什么你把事情搞砸了：你 重置(reset) 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。 这就是 git reflog 的目的， reflog 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次HEAD的改变, 一条新的记录就会增加到reflog。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。 1234(master)$ git reflog0a2e358 HEAD@&#123;0&#125;: reset: moving to HEAD~20254ea7 HEAD@&#123;1&#125;: checkout: moving from 2.2 to masterc10f740 HEAD@&#123;2&#125;: checkout: moving from master to 2.2 上面的reflog展示了从master分支签出(checkout)到2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 HEAD@{0}标识. 如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前master上指向的提交(0254ea7)。 1$ git reset --hard 0254ea7 然后使用git reset就可以把master改回到之前的commit，这提供了一个在历史被意外更改情况下的安全网。 (摘自). 其它资源(Other Resources)书(Books) Pro Git - Scott Chacon’s excellent git book Git Internals - Scott Chacon’s other excellent git book 教程(Tutorials) Learn Git branching 一个基于网页的交互式 branching/merging/rebasing 教程 Getting solid at Git rebase vs. merge git-workflow - Aaron Meurer的怎么使用Git为开源仓库贡献 GitHub as a workflow - 使用GitHub做为工作流的趣事, 尤其是空PRs 脚本和工具(Scripts and Tools) firstaidgit.io 一个可搜索的最常被问到的Git的问题 git-extra-commands - 一堆有用的额外的Git脚本 git-extras - GIT 工具集 – repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git小提示 git-town - 通用，高级Git工作流支持！ http://www.git-town.com GUI客户端(GUI Clients) GitKraken - 豪华的Git客户端 Windows, Mac &amp; Linux git-cola - 另外一个Git客户端 Windows &amp; OS X GitUp - 一个新的Git客户端，在处理Git的复杂性上有自己的特点 gitx-dev - 图形化的Git客户端 OS X Source Tree - 免费的图形化Git客户端 Windows &amp; OS X Tower - 图形化Git客户端 OS X(付费) SmartGit - 推荐，对个人用户免费","tags":[{"name":"飞行手册","slug":"飞行手册","permalink":"http://ruanxinyu.github.io/tags/飞行手册/"}]},{"title":"Ubuntu下Mysql+Keepalived双主热备高可用环境的搭建","date":"2018-10-04T04:50:27.000Z","path":"posts/Ubuntu下Mysql-Keepalived双主热备高可用环境的搭建/","text":"Mysql复制模式及原理Mysql内建的复制功能是构建大型，高性能应用程序的基础。Mysql将数据库的更改写入到二进制日志文件，而复制功能就是基于该日志完成的。Mysql的二进制日志格式也有三种：STATEMENT，ROW，MIXED。对应的是Mysql的三种复制模式. 复制原理master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；salve服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件，同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。过程如下： 注意几点： master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。 slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了。 Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。 Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本） master和slave两节点间时间需同步 主服务写入日志和从数据库回访日志都是串行的 注意：所有对表的操作都需要在主服务器上操作，否则会造成数据冲突 基于SQL语句的复制(SBR)基于SQL语句的复制(statement-based replication, SBR)的优点有： 产生的binlog文件较小，比较节省空间 binlog既可以用来复制，也可以用于实时的还原 主从版本可以不一样，从服务器版本可以比主服务器版本高。 缺点有： 不是所有的UPDATE语句都能被复制，尤其是包含不确定操作的时候。 调用具有不确定因素的 UDF 时复制也可能出问题，比如LOAD_FILE()，UUID()，USER()，FOUND_ROWS()，SYSDATE() INSERT ... SELECT 会产生比 RBR 更多的行级锁 基于行的复制(RBR)基于行的复制(row-based replication, RBR)的优点有： 任何情况都可以被复制，这对复制来说是最安全可靠的 多数情况下，从服务器上的表如果有主键的话，复制就会快了很多 执行 INSERT，UPDATE，DELETE 语句时锁更少 从服务器上采用多线程来执行复制成为可能 缺点有： binlog 文件太大 复杂的回滚时 binlog 中会包含大量的数据 主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写问题 UDF 产生的大 BLOB 值会导致复制变慢 无法从 binlog 中看到都复制了写什么语句，无法进行审计 混合模式复制(MBR)混合模式复制(mixed-based replication, MBR) 解决的问题Mysql支持主从复制模式和主主复制模式，能够解决以下的问题： 数据分布 (Data distribution ) 负载平衡(load balancing) 数据备份(Backups) ，保证数据安全 高可用性和容错行(High availability and failover) 实现读写分离，缓解数据库压力 基础环境说明本次教程搭建的架构图如下所示，通过Mysql的主从同步实现数据的同步，通过KeepAlived实现Mysql的故障时的自动切换，其中为192.168.1.132和192.168.1.133，VIP为192.168.1.134。 使用的Ubuntu是18.04.1版本：VirtualBox安装Ubuntu教程 使用的Mysql是8.0.12版本：Ubuntu下Mysql的安装与验证 使用的KeepAlived是2.0.7版本：Ubuntu下KeepAlived的安装与配置 Mysql的主从同步设置 用户配置文件位置：/etc/mysql/my.cnf pid文件位置：/var/run/mysqld/mysqld.pid socket文件位置：/var/run/mysqld/mysqld.sock 数据目录： /var/lib/mysql 错误日志文件： /var/log/mysql/error.log 配置my.cnf文件Mysql_01(192.168.1.132)编辑sudo vim /etc/mysql/my.cnf文件，添加如下内容： 12345[mysqld]log-bin=mysql-binrelay_log=mysql-relay-binserver-id=1log_slave_updates=1 Mysql_02(192.168.1.133)编辑sudo vim /etc/mysql/my.cnf文件，添加如下内容： 12345[mysqld]log-bin=mysql-binrelay_log=mysql-relay-binserver-id=2log_slave_updates=1 上述配置mysql的二进制日志的名称为mysql-bin，采用的是相对目录，具体绝对目录可以通过执行show variables like &#39;log_%&#39;;得到，如下所示 如上述配置指定了relay_log的值，否则mysql会自动根据主机的hostname命名，如果修改hostname的话可能就会出问题，在error.log中也可以看到对应的警告： 创建复制用户Mysql_01(192.168.1.132)中执行mysql -u root -p进入到mysql的控制台执行如下语句： 123CREATE USER 'repl'@'192.168.1.133' IDENTIFIED BY 'mysql';GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.1.133';FLUSH PRIVILEGES; Mysql_02(192.168.1.133)中执行mysql -u root -p进入到mysql的控制台执行如下语句： 123CREATE USER 'repl'@'192.168.1.132' IDENTIFIED BY 'mysql';GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.1.132';FLUSH PRIVILEGES; 执行CHANGE MASTER TO语句Mysql_01(192.168.1.132)中执行mysql -u root -p进入到mysql的控制台执行如下语句： 123456CHANGE MASTER TO MASTER_HOST='192.168.1.133', MASTER_USER='repl', MASTER_PASSWORD='mysql', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=0; Mysql_02(192.168.1.133)中执执行mysql -u root -p进入到mysql的控制台执行如下语句： 123456CHANGE MASTER TO MASTER_HOST='192.168.1.132', MASTER_USER='repl', MASTER_PASSWORD='mysql', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=0; MASTER_LOG_FILE用来指定初始复制时的mysql1中的binlog文件， MASTER_LOG_POS用来指定初始复制时binlog文件的位置 重启并查看同步状态 sudo systemctl restart mysql.service重启mysql mysql -u root -p进入到mysql的控制台执行start slave; 通过show slave status\\G;查看启动状态，如果出现下面的内容则表示成功 KeepAlived的配置Keepalived的安装请参考：Ubuntu下KeepAlived的安装与配置。配置文件主要有如下几点变化： 两台机器的state都设置为BACKUP，同时nopreempt配置，可以防止切换到从库后，主keepalived恢复后自动切换回主库 virtual_ipaddress改为192.168.1.134 vrrp_script中的命令改为netstat -na | grep LISTEN | grep 3306 || killall keepalived 特别说明: 此处仅仅简单的通过检查33060端口来判断mysql是否正常。你可以可以根据自己的需求，将该脚本设计的更复杂一些。比如根据数据库的插入、删除等是否可用、主从线程是否开启等进行细分。提高检测的精准度。 Mysql_01(192.168.1.132)中KeepAlived的配置如下： 1234567891011121314151617181920vrrp_script chk_service_ok &#123; script \"netstat -na | grep LISTEN | grep 3306 || killall keepalived\" interval 2&#125;vrrp_instance VI_1 &#123; interface enp0s3 state BACKUP # 通过下面的priority来区分MASTER和BACKUP，也只有如此，底下的nopreempt才有效 virtual_router_id 51 priority 100 nopreempt # 防止切换到从库后，主keepalived恢复后自动切换回主库 virtual_ipaddress &#123; 192.168.1.134/24 &#125; track_script &#123; chk_service_ok &#125;&#125; Mysql_02(192.168.1.133)中KeepAlived的配置如下： 1234567891011121314151617181920vrrp_script chk_service_ok &#123; script \"netstat -na | grep LISTEN | grep 3306 || killall keepalived\" interval 2&#125;vrrp_instance VI_1 &#123; interface enp0s3 state BACKUP # 通过下面的priority来区分MASTER和BACKUP，也只有如此，底下的nopreempt才有效 virtual_router_id 51 priority 80 nopreempt # 防止切换到从库后，主keepalived恢复后自动切换回主库 virtual_ipaddress &#123; 192.168.1.134/24 &#125; track_script &#123; chk_service_ok &#125;&#125; 配置完毕之后执行sudo systemctl restart keepalived重新启动keepalived。 功能验证正常情况下的验证首先，通过ip a可以看到VIP在Mysql_01(192.168.1.132)上： 在Mysql_01(192.168.1.132)上执行mysql -u root -p进入到mysql的控制台， 创建数据库create database database_01;;在Mysql_02(192.168.1.133)上执行mysql -u root -p进入到mysql的控制台， 创建数据库create database database_02;; 然后分别在两台机器上执行show databases；，可以看到两台mysql中都包含database_01和database_02，说明mysql的主主同步生效。 异常恢复下的验证Mysql_01(192.168.1.132)上执行sudo systemctl stop mysql.service停止mysql以模拟故障，此时可以看到VIP(192.168.1.134)已经漂移到mysql_02上，我们ssh连接VIP并往数据库中创建一个数据库create database database_vip;，可以看到是可以正常创建的，说明keepalived已经能保证mysql的高可用。 此时我们重新启动Mysql_01(192.168.1.132)以模拟故障恢复，此时发现VIP还在mysql_02上，同时Mysql_01的数据库中也已经存在database_vip数据库。说明故障恢复后数据仍旧能够正常同步。 常见操作说明彻底解除主从复制关系 stop slave reset slave; 或直接删除master.info和relay-log.info这两个文件 修改my.cnf删除主从相关配置参数 让slave不随MySQL自动启动修改my.cnf, 在[mysqld]中增加skip-slave-start选项 数据备份的快速恢复执行如下命令备份，可以保留 file 和 position 的信息，在新搭建一个slave的时候，还原完数据库， file 和 position 的信息也随之更新，接着再start slave 就可以很迅速的完成增量同步： 1mysqldump --master-data --single-transaction --user=username --password=password dbname&gt; dumpfilename 如何限制复制哪些数据库 在执行grant授权的时候就限定数据库 在主服务器上限定binlog_do_db = 数据库名 主服务器上不限定数据库，在从服务器上限定replicate-do-db = 数据库名 修改log-bin和relay_log后重启报错先执行reset slave，然后执行start slave即可。 日志出现[Warning] IP address &#39;xxxx&#39; could not be resolved: Name or service not knownmysql默认会反向解析DNS，对于访问者Mysql不会判断是hosts还是ip都会进行dns反向解析，我们可以通过在my.cnf中添加skip-name-resolve禁用dns反查即可。 主备同步报：Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs是因为数据目录下的/var/lib/mysql/auto.cnf文件是一样导致的，我们可以删除备机上的该文件，然后重启mysql","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"TypeScript学习记录-1","date":"2018-10-04T02:08:09.000Z","path":"posts/TypeScript学习记录-1/","text":"安装和编译使用npm进行安装： 1npm install -g typescript 使用tsc可以将ts文件编译为js文件： 1tsc greeter.ts 变量类型官方文档地址为：http://www.typescriptlang.org/docs/handbook/basic-types.html。基本的数据类型及使用如下所示： 1234567891011121314151617181920212223242526// booleanlet isDone: boolean = false;// numberlet decimal: number = 6;let hex: number = 0xf00d;let binary: number = 0b1010;let octal: number = 0o744;// 字符串即字符串中的变量引用let fullName: string = `Bob Bobbington`;let age: number = 37;let sentence: string = `Hello, my name is $&#123; fullName &#125;.I'll be $&#123; age + 1 &#125; years old next month.`;// 数组let list: number[] = [1, 2, 3];let list: Array&lt;number&gt; = [1, 2, 3];// 元组let x: [string, number] = [\"hello\", 10];// 枚举enum Color &#123;Red = 1, Green, Blue&#125;let c: Color = Color.Green; 还有其他的类型包括：any, void, null, undifined, never, object。 变量声明变量的声明有3个关键字var, let, const。 定义要尽可能使用let，而不是var const是针对不可以重新复制的变量 object的声明与json的定义方式是一样的 默认值123function keepWholeObject(wholeObject: &#123; a: string, b?: number &#125;) &#123; let &#123; a, b = 1001 &#125; = wholeObject;&#125; 函数声明1234type C = &#123; a: string, b?: number &#125;function f(&#123; a, b &#125;: C): void &#123; // ...&#125; 123456function f(&#123; a, b = 0 &#125; = &#123; a: \"\" &#125;): void &#123; // ...&#125;f(&#123; a: \"yes\" &#125;); // ok, default b = 0f(); // ok, default to &#123; a: \"\" &#125;, which then defaults b = 0f(&#123;&#125;); // error, 'a' is required if you supply an argument Spread12345678// 数组let first = [1, 2];let second = [3, 4];let bothPlus = [0, ...first, ...second, 5];// 对象let defaults = &#123; food: \"spicy\", price: \"$$\", ambiance: \"noisy\" &#125;;let search = &#123; ...defaults, food: \"rich\" &#125;; 接口通过interface定义接口，只要校验传进来的参数是否包含接口中的变量，则认为传进来的参数与接口是兼容的。可以通过?来指定是否是函数的可选参数，通过readonly来指定参数是只读的。 1234567891011121314151617181920interface SquareConfig &#123; color?: string; width?: number; readonly height?: number;&#125;function createSquare(config: SquareConfig): &#123; color: string; area: number &#125; &#123; let newSquare = &#123;color: \"white\", area: 100&#125;; if (config.clor) &#123; // Error: Property 'clor' does not exist on type 'SquareConfig' newSquare.color = config.clor; &#125; if (config.width) &#123; newSquare.area = config.width * config.width; &#125; return newSquare;&#125;let mySquare = createSquare(&#123;color: \"black\"&#125;);Readonly properties 接口中也是可以定义函数的。 接口可以通过extends来继承 类 通过class定义类，通过implements实现接口 通过constructor来定义构造函数 支持getter/setter方法 支持static关键字 支持abstract关键字 函数多参数支持 12345function buildName(firstName: string, ...restOfName: string[]) &#123; return firstName + \" \" + restOfName.join(\" \");&#125;let employeeName = buildName(\"Joseph\", \"Samuel\", \"Lucas\", \"MacKinzie\"); this和箭头函数Arrow functions capture the this where the function is created rather than where it is invoked. 所以在定义函数的时候尽量使用箭头函数，如果使用this的时候提示是any类型，可以显性的传入this变量 12345678910111213141516171819202122232425262728interface Card &#123; suit: string; card: number;&#125;interface Deck &#123; suits: string[]; cards: number[]; createCardPicker(this: Deck): () =&gt; Card;&#125;let deck: Deck = &#123; suits: [\"hearts\", \"spades\", \"clubs\", \"diamonds\"], cards: Array(52), // 显性的传入this createCardPicker: function(this: Deck) &#123; // 是哟弄个箭头函数 return () =&gt; &#123; let pickedCard = Math.floor(Math.random() * 52); let pickedSuit = Math.floor(pickedCard / 13); return &#123;suit: this.suits[pickedSuit], card: pickedCard % 13&#125;; &#125; &#125;&#125;let cardPicker = deck.createCardPicker();let pickedCard = cardPicker();alert(\"card: \" + pickedCard.card + \" of \" + pickedCard.suit); 泛型函数 12345function identity&lt;T&gt;(arg: T): T &#123; return arg;&#125;let myIdentity: &#123;&lt;T&gt;(arg: T): T&#125; = identity; // 类 123456class GenericNumber&lt;T&gt; &#123; zeroValue: T; add: (x: T, y: T) =&gt; T;&#125;let myGenericNumber = new GenericNumber&lt;number&gt;(); 类继承 12345678interface Lengthwise &#123; length: number;&#125;function loggingIdentity&lt;T extends Lengthwise&gt;(arg: T): T &#123; console.log(arg.length); // Now we know it has a .length property, so no more error return arg;&#125;","tags":[{"name":"前端 学习记录","slug":"前端-学习记录","permalink":"http://ruanxinyu.github.io/tags/前端-学习记录/"}]},{"title":"Jenkins的安装与使用","date":"2018-10-03T09:01:53.000Z","path":"posts/Jenkins的安装与使用/","text":"Jenkins的介绍官方地址为：https://jenkins.io/。Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。 Jenkins的安装 在启动之前需要先安装java环境，具体可以参考教程：JDK安装教程。该教程使用的Ubuntu版本是18.04.1版本，Ubuntu的安装教程参考VirtualBox安装Ubuntu教程。 具体的安装文档可以参考：https://jenkins.io/doc/book/installing/。 文档中直接通过sudo apt-get install jenkins的方式安装会报错，不兼容最新版本的Ubuntu系统，因此下文采用直接下载软件包安装的过程。 首先下载http://mirrors.jenkins.io/war-stable/latest/jenkins.war软件包，然后执行java -jar jenkins.war即可启动Jenkins。默认情况下Jenkins会监听8080端口，我们可以通过如下命令修改端口号java -jar jenkins.war --httpPort=9090。 访问http://192.168.1.108:8080/，可以看到如下的页面，提示输入密码，可以从界面中找到密码所在的文件路径，或者从启动日志中也可以看到。 修改Jenkins的主目录从Jenkins的启动日志中可以看出Jenkins默认的主目录为$user.home/.jenkins，我们在此将其主目录更改至/usr/local/jenkins/.jenkins，只需要导出环境JENKINS_HOME环境变量exprot JENKINS_HOME=/usr/local/jenkins/.jenkins，然后启动Jenkins即可。 系统服务与开机启动","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"SonatypeNexus的安装与使用","date":"2018-10-02T10:21:06.000Z","path":"posts/SonatypeNexus的安装与使用/","text":"SonatypeNexus的介绍Sonatype Nexus可以用来作为Maven/Java, npm, NuGet, RubyGems, Docker, P2, OBR, APT and YUM等的代理仓和私有仓库，同时还与Eclipse, IntelliJ, Hudson, Jenkins, Puppet, Chef, Docker等工具有很好的集成。那么我们在开发中可以用SonatypeNexus做什么呢？ 代理并缓存Maven/npm/docker等中央仓，提升下载速度 作为Maven/npm/docker等的私有仓库，上传私有组件 作为编译构建仓库，用于分享或者部署到环境 SonatypeNexus的安装 在启动之前需要先安装java环境，具体可以参考教程：JDK安装教程。另外Nexus对内存要求比较大，请至少保持2G以上的内存。 Linux下源码安装的脚本可以点击此处下载： nexus_install.sh，下面对安装过程做一下说明。 SonatypeNexus的下载地址为： https://help.sonatype.com/repomanager3/download/download-archives—repository-manager-3 Linux通过如下命令下载并解压： 123wget http://download.sonatype.com/nexus/3/nexus-3.13.0-01-unix.tar.gzsudo tar -zxvf nexus-3.13.0-01-unix.tar.gz -C /usr/local/nexussudo chown -R $(whoami):$(whoami) /usr/local/nexus Windows点击http://download.sonatype.com/nexus/3/nexus-3.13.0-01-win64.zip下载后解压到本地磁盘 解压后，有nexus-3.13.0-01和sonatype-work两个目录： nexus-3.13.0-01是软件目录，升级SonatypeNexus版本是只需要替换这个目录即可 sonatype-work是数据目录，所有配置信息，软件包都在这个目录 SonatypeNexus的启动进入到Nexus的安装目录nexus-3.13.0-01/bin/nexus, Linux执行./nexus start即可启动。查看启动日志在tail -100f sonatype-work/nexus3/log/nexus.log，当日志中出现如下的字样时表示nexus已经启动成功。 Windows下执行nexus.exe /run即可启动。 默认情况下，Nexus监听的端口号为8081，我们通过浏览器访问就可以看到Nexus的页面，默认的用户名为admin，密码为admin123。 系统服务与开机启动我们还是采用systemd的方式添加到系统服务，执行如下命令： 12345678910111213141516171819202122(cat &lt;&lt;EOF[Unit]Description=Sonatyp Nexus DaemonAfter=network.targetWants=network-online.target[Service]Type=forkingLimitNOFILE=65536ExecStart=/usr/local/nexus/nexus-3.13.0-01/bin/nexus startExecStop=/usr/local/nexus/nexus-3.13.0-01/bin/nexus stopUser=$(whoami)Restart=on-abort[Install]WantedBy=multi-user.targetEOF) &gt; nexus.servicesudo cp -a nexus.service /lib/systemd/system/nexus.servicesudo ln -s /lib/systemd/system/nexus.service /etc/systemd/system/multi-user.target.wants/nexus.service 然后启动并添加为开机启动： 12sudo systemctl start nexussudo systemctl enable nexus Nexus启动不起来的可能原因: 没有安装java，可以通过java -version进行测试 当前用户没有nexus所在目录的权限，可以在执行用户下执行sudo chown -R $(whoami):$(whoami) /usr/local/nexus SonatypeNexus的配置配置最大文件句柄数在Nexus的界面中可以看到提示System Requirement: max file descriptors [4096] likely too low, increase to at least [65536].，点击进去可以看到具体的设置方式，如果采用上文中的systemd的方式启动nexus，则不存在这个问题，因为我们已经在nexus.service中设置最大文件句柄数LimitNOFILE=65536。 注意：设置完该参数后需要重新启动进程才可以生效。","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"我的博客规划路线图","date":"2018-10-02T07:56:46.000Z","path":"posts/我的博客规划路线图/","text":"我对于博客建设的思考为什么要写博客？写博客有两个目的，一个是促进知识的内化，二是提升自己的影响力。 以教为学是一个很好的学习方式，而且现在信息太多，如果不经过自己整理归纳，那就很容易成为知识收藏者，而不是知识的产生者和传播者，显然我是希望成为后者的，我希望通过将知识体系化从而提升自己的核心竞争力。 影响力有两个很重要的作用，一个是提升收入，一个是提升满足感，这对我都很重要。如何建立影响力？建立品牌并服务他人，对于身边的人，还可以通过行为来影响，但是对于陌生人只能通过分享，因此内容建设很重要，博客是其中一个途径。 如何选择博客内容？博客内容选择需要考虑三个点：独特性，体系化，刚需。 独特性有两个方面，对于自己，因为要建立T型或者E型人才，所以要确定哪些内容需要深度，哪些内容需要广度；对于外部读者，如果博文是网上没有的，这样用户搜索肯定就会搜到你的，这肯是独特的，但是这样的主题能找到，但是可能不多，这个依赖于自己的观察，比如说Nexus的源码分析。 更多的时候博文内容网上通篇都是，那么用户为什么要看你的，那么这个地方就需要考虑体系化和刚需。内容不能太分散，需要成体系化，这样才能让博文之间产生关联性，提高点击率，产生用户粘性。谈到刚需，那么必然要谈到用户群体，我针对的是初级用户，比如未出学校的大学生和刚入职场的新人，因为他们可能缺少实际的项目经验，因此他们缺少体系化的认识，那么我就正好可以以我自己为例，为用户构建一个成长为T型人才的路径，这也和我自己的目标是一致的。所以博客的文章是可以零散的，但是文章之间的关系必须是体系化，场景化的。 博客不仅限于技术的分享，因为我的目标是让自己过得更好，那么在心理学，历史学，经济学，个人成长等领域也是可以总结和分享，以一个点为起点，逐步向周边辐射，扩展维度，这样才能保持自己的独特性。用20%的时间学习一个领域的80%内容，而不是用80%的时间将一个维度提升至90%，这样才能实现跨学科之间的创新性，当然，在这个过程中，在某一个核心领域还是要长期保持深入学习的。 对于心理学，历史学，经济学，个人成长其实更多的是以读书笔记为重点，通过得到App课程和主题阅读将内容体系化。 技术规划路线我是搞软件开发的，因此技术规划也就是软件行业的。因为代码能力需要多写，而且内容更零散的，而架构能力更能体现出体系化，因此我分享更多的是架构能力，基于不同场景使用不同架构，通过一步一步的搭建系统架构来帮助用户提升整体认识。每一个主题都有一个总体的架构图作为目标，为了达到这个目标，我们会分解目标逐步完成，分步验证。 【进行中】 Nginx-HAProxy-KeepAlived-Tomcat-MySQL等搭建高可用系统 【等待中】 搭建基于SpringCloud的高可用生产系统 【等待中】 如何从头开始搭建持续交付系统 Nginx-HAProxy-KeepAlived-Tomcat-MySQL等搭建高可用系统","tags":[{"name":"技术分享","slug":"技术分享","permalink":"http://ruanxinyu.github.io/tags/技术分享/"}]},{"title":"Ubuntu下Nginx的安装与配置","date":"2018-10-02T06:19:56.000Z","path":"posts/Ubuntu下Nginx的安装与配置/","text":"Nginx的简介官方网址：http://nginx.org/。 Nginx可以作为http服务器、反向代理服务器、邮件服务器和负载均衡服务器等功能，具有性能高、扩展灵活等特点，能够快速的响应静态网页的请求，支持FastCGI/SSL/Virtual Host/URL Rwrite/Gzip/HTTP Basic Auth等功能，并且支持丰富的第三方扩展功能。 Nginx的安装该教程使用的Ubuntu版本是18.04.1版本，Ubuntu的安装教程参考VirtualBox安装Ubuntu教程。Nginx可以直接通过apt-get安装，也可以通过源码编译安装。 apt-get安装Ubuntu下执行sudo apt-get install nginx命令即可安装。 通过which nginx可以看到Nginx是安装在/usr/sbin/nginx下，配置文件在/etc/nginx/目录下。 源码编译安装源码安装的脚本可以点击此处下载： nginx_install.sh，下面对安装过程做一下说明。 首先安装编译工具和openssl，下载Nginx源码并解压，然后执行源码编译三件套（./configure &amp;&amp; make &amp;&amp; make install），我们安装的目录为/usr/local/nginx： 123456789sudo apt-get install build-essential libssl-dev # 安装编译工具和openssl依赖sudo apt-get install zlib1g-devsudo apt-get install libpcre3 libpcre3-devwget http://nginx.org/download/nginx-1.15.4.tar.gz # 下载源码tar -zxvf nginx-1.15.4.tar.gz # 解压源码cd nginx-1.15.4/./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_v2_module --with-http_gzip_static_module --with-http_sub_module --with-pcre --with-http_ssl_module # 配置nginx的安装参数，可以根据自己的需要进行调整make # 编译源码sudo make install # 安装到安装目录，需要使用root权限 Nginx的启动和关闭Nginx的启动直接使用/usr/local/nginx/sbin/nginx, 在源码安装下使用的配置文件是/usr/local/nginx/conf/nginx.conf，通过/usr/local/nginx/sbin/nginx -s reload命令重新加载, 可以通过/usr/local/nginx/sbin/nginx -s stop停止进程 Nginx的开机启动方式1：rc.local编辑sudo vim /etc/rc.local, 在最下面添加sudo /usr/local/nginx/sbin/nginx语句即可。 方式2：systemctl我们还是采用systemd的方式添加到系统服务，执行如下命令： 12345678910111213141516171819202122(cat &lt;&lt;EOF[Unit]Description=Nginx DaemonAfter=syslog.target network-online.targetWants=network-online.targetConditionFileNotEmpty=/usr/local/nginx/conf/nginx.conf[Service]Type=forkingKillMode=processExecStart=/usr/local/nginx/sbin/nginxExecStop=/usr/local/nginx/sbin/nginx -s stopExecReload=/usr/local/nginx/sbin/nginx -s reload[Install]WantedBy=multi-user.targetEOF) &gt; nginx.servicesudo cp -a nginx.service /lib/systemd/system/nginx.servicesudo ln -s /lib/systemd/system/nginx.service /etc/systemd/system/multi-user.target.wants/nginx.service 启动Nginx进程，并设置为开机启动，通过sudo systemctl status nginx查看状态： 123sudo systemctl start nginxsudo systemctl status nginxsudo systemctl enable nginx Nginx的配置 Nginx功能强大，配置无法简单描述，因此，下文仅以一个最简单的静态文件服务器为例进行说明验证，更多的应用场景将会在其他的文章中进行说明。 配置文件是/usr/local/nginx/conf/nginx.conf，源码安装后默认的配置文件就已经提供了静态文件服务器的配置，我们增加autoindex on;参数以便后续更加方便的验证功能，如下所示： 12345678910111213141516171819202122232425262728worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; location / &#123; root html; # 设置静态文件服务的本地目录为html目录 autoindex on; # 增加该参数以便自动生成文件目录 index index.html index.htm; # 默认访问文件夹下的index.html &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 通过上面的配置可以看出，配置文件包含全局的配置、events和http等几部分，其中http表示定义了一个HTTP服务器，其中包含一个server监听本地机器的80端口，server中的location用来定义网址路由，通过root用来定义静态文件服务的本地目录，此处指定的是nginx安装目录下的html目录/usr/local/nginx/html/. Nginx的验证采用nginx的默认配置启动nginx，此时通过浏览器访问80端口即可以看到如下的页面，即/usr/local/nginx/html/index.html的内容。 我们在/usr/local/nginx/html/下创建一些文件夹和文件cd /usr/local/nginx/html/ &amp;&amp; sudo mkdir -p aa/aa aa/bb aa/cc aa/dd &amp;&amp; sudo touch aa/a.txt，可以通过浏览器看到对应的文件：","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"阿里ACA认证学习记录","date":"2018-09-28T07:23:31.000Z","path":"posts/阿里ACA认证学习记录/","text":"大数据概述大数据，指无法在可承受的时间范围内用常规软件工具进行捕捉，管理和处理的数据集合，是需要新处理模式才能具有更强的决策力，洞察发现力和流程优化能力的海量，高增长率和多样化的信息资产。 大数据的主要特征：4V 数据分析流程 Hadoop生态圈 阿里云大数据体系 数加的定位 统一的大数据计算平台 分析型数据库分析型数据库的介绍OLAP，OLTP，维度和度量，下钻，下图中时间，地区和产品就是维度，而销量和金额就是度量 MPP（大规模并行处理， Massive Parallel Processing） 分析型数据库：高并发在线分析（Realtime OLAP），与关系型数据库的区别是分析型数据库没有事务，是专门用于分析的，支持sql语句，但是跟关系型数据库没有什么关系 分析型数据库的基本概念表组 表组的特点 维表的特点，以空间换时间 事实表的特点 数据类型 多值列，不满足3范式，性能明显优于join 分析型数据库的基本操作DMS在表组中新建表 MaxComputeMaxCompute的介绍大数据计算服务 对象 分区 分区表 分区举例 其他概念， 执行sql都是task，是异步的 数据类型 阿里小贷 大数据架构 MaxCompute的架构介绍客户端 逻辑层 计算层 数据上传 数据下载 参数 分隔符 DDL的介绍创建表 表的生命周期，比如用来保持最近7天的数据 快捷建表 分区操作 修改表属性 视图操作 DML的介绍查询操作 更新数据 多路输出 表关联 MapJoin MapJoin举例 分支表达式 内置函数数学运算函数-1 数学运算函数-2 字符串处理函数 日期类型处理函数 窗口函数 聚合函数 其他函数 其他使用方式自定义函数 UDF开发流程 MapReduce介绍 MR框架 Graph 如何使用合适的方式 授权授权 添加用户授权 角色管理 DataIDEDataIDE介绍产品概述 开发流程-1 开发流程-2 应用场景 DataIDE基本概念概念 角色 多环境 演示：任务调度 节点任务 工作流任务 演示：数据同步数据源 创建任务 选择来源 选择目标 字段映射 通道控制 数据管理数据管理 运维中心 项目管理 QuickBI报表QuickBI的介绍产品概述 产品架构 角色定位 常见应用步骤 QuickBI的数据管理数据源管理 数据集管理 首页 新建数据源 表格分析 图表与门户-常见图标 图表 门户 DataV数据大屏产品介绍产品概述 特性1：多重场景模板 特性2：丰富开放的图表库 特性3：支持多种数据源 特性4：零门槛图形化界面设计 特性5，支持数据交互分析 特性6：支持适配与发布方式 DataV大屏介绍展示类大屏 展示类大屏示例 分析类大屏 分析类大屏示例 监控类大屏 监控类大屏示例 可视化大屏设计原则 大屏样例1 大屏样例2 DataV演示添加数据 视频和样例 创建大屏-1 创建大屏-2","tags":[{"name":"大数据 学习记录","slug":"大数据-学习记录","permalink":"http://ruanxinyu.github.io/tags/大数据-学习记录/"}]},{"title":"Ubuntu下搭建HAProxy+KeepAlived高可用集群","date":"2018-09-28T02:48:23.000Z","path":"posts/Ubuntu下搭建HAProxy-KeepAlived高可用集群/","text":"环境说明本次教程搭建的架构图如下所示，通过KeepAlived实现HAProxy的高可用，通过HAProxy实现后端服务器App01和App02的高可用和负载均衡。HAPrxoy有两台，分别为192.168.1.102和192.168.1.103，VIP为192.168.1.104，通过8081端口访问App01的两台机器，通过8082端口访问App02的两台机器。 本教程使用Ubuntu 18.04.01系统，同时需要安装KeepAlived和HAProxy，相关的教程请参考： VirtualBox安装Ubuntu教程 Ubuntu下KeepAlived的安装与配置 Ubuntu下HAProxy的安装与配置 HAProxy的配置两台HAProxy的配置是相同的，通过8081端口访问App01的两台机器，通过8082端口访问App02的两台机器。为了简化配置过程，还是采用最简化的配置，如下所示： 12345678910111213141516171819202122232425262728293031global daemon # 配置为后台启动defaults mode http timeout connect 30s # 连接超时 timeout client 30s # 客户端超时 timeout server 30s # 服务器超时###########################################################frontend app01 bind *:8081 # 绑定端口 default_backend app01_backend # 默认的backend的名称backend app01_backend server web1 192.168.1.106:80 # 设置后端服务器 server web1 192.168.1.108:80 # 设置后端服务器###########################################################frontend app02 bind *:8082 # 绑定端口 default_backend app02_backend # 默认的backend的名称backend app02_backend server web1 192.168.1.107:80 # 设置后端服务器 server web1 192.168.1.109:80 # 设置后端服务器###########################################################listen stats bind *:8083 # 设置监控组的名称 stats refresh 30s # 统计页面自动刷新时间 stats uri /stats # 统计页面url KeepAlived的配置KeepAlived与HAProxy是在相同机器上，IP地址分别为主机haproxy_vm01（192.168.1.102）和备机haproxy_vm02（192.168.1.103）， VIP为192.168.1.104。因为KeepAlived是主备的，因此两台机器的配置是不一样的。 主机haproxy_vm01（192.168.1.102）的配置如下： 12345678910111213141516171819vrrp_script chk_service_ok &#123; script \"killall -0 haproxy\" interval 2&#125;vrrp_instance VI_1 &#123; interface enp0s3 state MASTER virtual_router_id 51 priority 100 virtual_ipaddress &#123; 192.168.1.104/25 &#125; track_script &#123; chk_service_ok &#125;&#125; 备机haproxy_vm02（192.168.1.103）的配置如下，相对于haproxy_vm01，只修改state和priority: 12345678910111213141516171819vrrp_script chk_service_ok &#123; script \"killall -0 haproxy\" interval 2&#125;vrrp_instance VI_1 &#123; interface enp0s3 state BACKUP virtual_router_id 51 priority 80 virtual_ipaddress &#123; 192.168.1.104/25 &#125; track_script &#123; chk_service_ok &#125;&#125; 通过上述配置可以看到，检查haproxy是否可用使用的是killall -0 haproxy命令来判断haproxy的进程是否存在。 App服务的配置我们后台采用apache，首先在每一台后台机器安装apache，我们使用Apache服务器来模拟HAProxy后端的服务器，sudo apt-get install apache2。 为了区分App01和App02，我们做如下操作： 在App01的两台机器执行sudo sh -c &#39;echo &quot;This is apache server 01&quot; &gt; /var/www/html/index.html&#39; 在App02的两台机器执行sudo sh -c &#39;echo &quot;This is apache server 02&quot; &gt; /var/www/html/index.html&#39; 高可用功能验证分别重新启动KeepAlived（sudo systemctl restart keepalived）和HAProxy（sudo systemctl restart haproxy）, 在HAProxy的两台机器上通过ip a命令，可以看到VIP（192.168.1.104）在haproxy_vm01（192.168.1.102）上. 通过VIP访问8081和8082端口，可以发现能够正常访问到后台的服务器，如下所示，此时我们关闭haproxy_vm01（192.168.1.102）上的HAproxy进程sudo killall haproxy，通过ip a可以看到VIP已经漂移到haproxy_vm02（192.168.1.103）上，但是通过VIP访问8081和8082端口，业务仍旧是正常的，说明HAProxy是高可用的。 我们关闭App01_vm01（192.168.1.106)，然后通过VIP访问8081端口，依旧可以正常访问，说明HAProxy已经保证后端App的高可用。","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"Ubuntu下HAProxy的安装与配置","date":"2018-09-24T23:07:50.000Z","path":"posts/Ubuntu下HAProxy的安装与配置/","text":"HAProxy的简介HAProxy是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。 HAProxy实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数，特别适用于那些负载特大的web站点，完全可以支持数以万计的并发连接，根据官方文档，haproxy可以跑满10Gbps。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的web服务器不被暴露到网络上。 HAProxy支持全透明代理，可以用客户端IP地址或者任何其他地址来连接后端服务器，同时提供连接拒绝功能，可以有效的限制攻击蠕虫。 HAProxy的安装该教程使用的Ubuntu版本是18.04.1版本，Ubuntu的安装教程参考VirtualBox安装Ubuntu教程。HAProxy可以直接通过apt-get安装，也可以通过源码编译安装。 apt-get安装Ubuntu下执行sudo apt-get install haproxy命令即可安装。 通过which haproxy可以看到KeepAlived是安装在/usr/sbin/haproxy下，HAProxy的配置文件路径为：/etc/haproxy/haproxy.cfg 使用sudo haproxy -f /etc/haproxy/haproxy.cfg即可启动HAProxy。 源码编译安装源码安装的脚本可以点击此处下载： haproxy_install.sh，下面对安装过程做一下说明。 一般源码安装目录为/usr/local/haproxy，在源码目录中的README文件有安装说明，下面罗列出几点内容： 在执行make命令之前是不需要执行./configure命令的，因此执行的参数都在make命令中指定 我们操作系统为Ubuntu 18.04.1，不涉及嵌入式编译，因此使用TARGET=linux26 ARCH=x86_64参数 PCRE(Perl Compatible Regular Expressions)的速度是其他的2-10倍，因此添加USE_PCRE=1选项，但是前提需要安装libpcre3 libpcre3-dev 为支持HTTPS协议，我们需要添加USE_OPENSSL=1选项，但是前提需要安装libssl-dev 为支持HTTP的压缩功能，我们需要添加USE_ZLIB=1，但是前提需要安装zlib1g-dev 为了保证安装目录为/usr/local/haproxy，我们需要在make install命令中指定PREFIX参数 1234567891011sudo apt-get install build-essential libssl-dev # 安装编译工具和openssl依赖sudo apt-get install zlib1g-devsudo apt-get install libpcre3 libpcre3-devwget https://www.haproxy.org/download/1.8/src/haproxy-1.8.8.tar.gz # 下载源码tar -zxvf haproxy-1.8.8.tar.gz # 解压源码cd haproxy-1.8.8/make TARGET=linux26 ARCH=x86_64 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 # 编译源码，从README中可以看出如何编译sudo make install PREFIX=/usr/local/haproxy # 安装到安装目录，需要使用root权限sudo mkdir -p /etc/haproxysudo cp -a examples/transparent_proxy.cfg /etc/haproxy/haproxy.cfg 启动HAProxy: sudo /usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg 可能遇到的问题 提示make is not found 源码安装需要安装编译器将源码转换为二进制可执行文件，因此执行sudo apt-get install build-essential安装编译器即可 启动时提示parsing [/etc/haproxy/haproxy.cfg:12] : unknown keyword &#39;ca-base&#39; in &#39;global&#39; section 编译haproxy时没有使能openssl的支持，安装libssl-dev并在编译时指定USE_OPENSSL=1选项即可 开机启动方式1：rc.local编辑sudo vim /etc/rc.local, 在最下面添加sudo /usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg语句即可。 方式2：systemctl我们还是采用systemd的方式添加到系统服务，执行如下命令： 123456789101112131415161718192021(cat &lt;&lt;EOF[Unit]Description=HAproxy DaemonAfter=syslog.target network-online.targetWants=network-online.targetConditionFileNotEmpty=/etc/haproxy/haproxy.cfg[Service]Type=forkingKillMode=processExecStart=/usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfgExecReload=/bin/kill -HUP $MAINPID[Install]WantedBy=multi-user.targetEOF) &gt; haproxy.servicesudo cp -a haproxy.service /lib/systemd/system/haproxy.servicesudo ln -s /lib/systemd/system/haproxy.service /etc/systemd/system/multi-user.target.wants/haproxy.service 启动keepalived进程，并设置为开机启动，通过sudo systemctl status haproxy查看状态： 123sudo systemctl start haproxy # 注意： 如果配置文件不正确的话HPAProxy是启动不起来的sudo systemctl status haproxysudo systemctl enable haproxy HAProxy的配置下面我们以一个最简单的用例说明如何配置HAProxy，架构图如下，192.168.1.102上安装有HAProxy, 8081端口转向192.168.1.106服务器，8082端口转向192.168.1.107服务器。因为HAProxy是提供有统计功能的，因此打开该功能，并监听在8083端口。 配置HAProxy编辑sudo vim /etc/haproxy/haproxy.cfg文件，写入如下的内容： 1234567891011121314151617181920212223242526272829global daemon # 配置为后台启动defaults mode http timeout connect 30s # 连接超时 timeout client 30s # 客户端超时 timeout server 30s # 服务器超时###########################################################frontend app01 bind *:8081 # 绑定端口 default_backend app01_backend # 默认的backend的名称backend app01_backend server web1 192.168.1.106:80 # 设置后端服务器###########################################################frontend app02 bind *:8082 # 绑定端口 default_backend app02_backend # 默认的backend的名称backend app02_backend server web1 192.168.1.107:80 # 设置后端服务器###########################################################listen stats bind *:8083 # 设置监控组的名称 stats refresh 30s # 统计页面自动刷新时间 stats uri /stats # 统计页面url 然后执行sudo /usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg启动HAProxy，通过sudo netstat -lntp | grep haproxy，可以看出HAProxy已经监听配置文件中的三个端口： 可能遇到的问题 启动时提示unknown keyword，如下所示： 从错误信息中可以看出keyword前都多了好多空格，说明我们的配置文件没有正确的使用tab键 启动HAProxy后配置文件没有生效 因为之前启动的HAProxy进程没有关闭，可以执行sudo killall haproxy关闭进程。 搭建Apache服务器我们使用Apache服务器来模拟HAProxy后端的服务器，首先分别在192.168.1.106和192.168.1.107两台机器上执行sudo apt-get install apache2，完成后Apache会自动启动并监听80端口，此时在浏览器中访问对应机器，既可以看到Apache2的首页，默认使用的首页文件路径为/var/www/html/index.html。 为了对两台机器做一下区分，我们做如下操作： 在192.168.1.106执行sudo sh -c &#39;echo &quot;This is apache server 01&quot; &gt; /var/www/html/index.html&#39; 在192.168.1.107执行sudo sh -c &#39;echo &quot;This is apache server 02&quot; &gt; /var/www/html/index.html&#39; 此时分别访问http://192.168.1.106/和http://192.168.1.107/可以看到下面的界面： HAProxy的验证此时访问HAProxy（192.168.1.102）的8081和8082可以看到分别访问到后端的192.168.1.106和192.168.1.107的80端口，如下所示，说明HAProxy的功能已经生效。 访问HAProxy的8083端口：http://192.168.1.102:8083/stats，可以看到HAProxy自带的的统计数据页面，如下所示： HAProxy详细配置说明（高级）对于初级使用者可以不必详细掌握所有的配置，只需要在使用的时候能查到即可，因此将说明放置在此处，参数说明来源于https://www.linuxidc.com/Linux/2012-07/65350.htm 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149####################全局配置信息###############################参数是进程级的，通常和操作系统（OS）相关#########global maxconn 20480 #默认最大连接数 log 127.0.0.1 local3 #[err warning info debug] chroot /var/haproxy #chroot运行的路径 uid 99 #所属运行的用户uid gid 99 #所属运行的用户组 daemon #以后台形式运行haproxy nbproc 1 #进程数量(可以设置多个进程提高性能) pidfile /var/run/haproxy.pid #haproxy的pid存放路径,启动进程的用户必须有权限访问此文件 ulimit-n 65535 #ulimit的数量限制#####################默认的全局设置########################这些参数可以被利用配置到frontend，backend，listen组件##defaults log global mode http #所处理的类别 (#7层 http;4层tcp ) maxconn 20480 #最大连接数 option httplog #日志类别http日志格式 option httpclose #每次请求完毕后主动关闭http通道 option dontlognull #不记录健康检查的日志信息 option forwardfor #如果后端服务器需要获得客户端真实ip需要配置的参数，可以从Http Header中获得客户端ip option redispatch #serverId对应的服务器挂掉后,强制定向到其他健康的服务器 option abortonclose #当服务器负载很高的时候，自动结束掉当前队列处理比较久的连接 stats refresh 30 #统计页面刷新间隔 retries 3 #3次连接失败就认为服务不可用，也可以通过后面设置 balance roundrobin #默认的负载均衡的方式,轮询方式 # balance source #默认的负载均衡的方式,类似nginx的ip_hash # balance leastconn #默认的负载均衡的方式,最小连接 contimeout 5000 #连接超时 clitimeout 50000 #客户端超时 srvtimeout 50000 #服务器超时 timeout check 2000 #心跳检测超时####################监控页面的设置#######################listen admin_status #Frontend和Backend的组合体,监控组的名称，按需自定义名称 bind 0.0.0.0:65532 #监听端口 mode http #http的7层模式 log 127.0.0.1 local3 err #错误日志记录 stats refresh 5s #每隔5秒自动刷新监控页面 stats uri /admin?stats #监控页面的url stats realm itnihao\\ itnihao #监控页面的提示信息 stats auth admin:admin #监控页面的用户和密码admin,可以设置多个用户名 stats auth admin1:admin1 #监控页面的用户和密码admin1 stats hide-version #隐藏统计页面上的HAproxy版本信息 stats admin if TRUE #手工启用/禁用,后端服务器(haproxy-1.4.9以后版本) rrorfile 403 /etc/haproxy/errorfiles/403.http rrorfile 500 /etc/haproxy/errorfiles/500.http rrorfile 502 /etc/haproxy/errorfiles/502.http rrorfile 503 /etc/haproxy/errorfiles/503.http rrorfile 504 /etc/haproxy/errorfiles/504.http#################HAProxy的日志记录内容设置################### capture request header Host len 40 capture request header Content-Length len 10 capture request header Referer len 200 capture response header Server len 40 capture response header Content-Length len 10 capture response header Cache-Control len 8#######################网站监测listen配置################################此用法主要是监控haproxy后端服务器的监控状态############listen site_status bind 0.0.0.0:1081 #监听端口 mode http #http的7层模式 log 127.0.0.1 local3 err #[err warning info debug] monitor-uri /site_status #网站健康检测URL，用来检测HAProxy管理的网站是否可以用，正常返回200，不正常返回503 acl site_dead nbsrv(server_web) lt 2 #定义网站down时的策略当挂在负载均衡上的指定backend的中有效机器数小于1台时返回true acl site_dead nbsrv(server_blog) lt 2 acl site_dead nbsrv(server_bbs) lt 2 monitor fail if site_dead #当满足策略的时候返回503，网上文档说的是500，实际测试为503 monitor-net 192.168.16.2/32 #来自192.168.16.2的日志信息不会被记录和转发 monitor-net 192.168.16.3/32########frontend配置#################注意，frontend配置里面可以定义多个acl进行匹配操作########frontend http_80_in bind 0.0.0.0:80 #监听端口，即haproxy提供web服务的端口，和lvs的vip端口类似 mode http #http的7层模式 log global #应用全局的日志配置 option httplog #启用http的log option httpclose #每次请求完毕后主动关闭http通道，HA-Proxy不支持keep-alive模式 option forwardfor #如果后端服务器需要获得客户端的真实IP需要配置次参数，将可以从Http Header中获得客户端IP ########acl策略配置############# acl itnihao_web hdr_reg(host) -i ^(www.itnihao.cn|ww1.itnihao.cn)$ #如果请求的域名满足正则表达式中的2个域名返回true -i是忽略大小写 acl itnihao_blog hdr_dom(host) -i blog.itnihao.cn #如果请求的域名满足www.itnihao.cn返回true -i是忽略大小写 #acl itnihao hdr(host) -i itnihao.cn #如果请求的域名满足itnihao.cn返回true -i是忽略大小写 #acl file_req url_sub -i killall= #在请求url中包含killall=，则此控制策略返回true,否则为false #acl dir_req url_dir -i allow #在请求url中存在allow作为部分地址路径，则此控制策略返回true,否则返回false #acl missing_cl hdr_cnt(Content-length) eq 0 #当请求的header中Content-length等于0时返回true########acl策略匹配相应############# #block if missing_cl #当请求中header中Content-length等于0阻止请求返回403 #block if !file_req || dir_req #block表示阻止请求，返回403错误，当前表示如果不满足策略file_req，或者满足策略dir_req，则阻止请求 use_backend server_web if itnihao_web #当满足itnihao_web的策略时使用server_web的backend use_backend server_blog if itnihao_blog #当满足itnihao_blog的策略时使用server_blog的backend #redirect prefix http://blog.itniaho.cn code 301 if itnihao #当访问itnihao.cn的时候，用http的301挑转到http://192.168.16.3 default_backend server_bbs #以上都不满足的时候使用默认server_bbs的backend##########backend的设置###############下面我将设置三组服务器 server_web，server_blog，server_bbs##################backend server_web####################backend server_web mode http #http的7层模式 balance roundrobin #负载均衡的方式，roundrobin平均方式 cookie SERVERID #允许插入serverid到cookie中，serverid后面可以定义 option httpchk GET /index.html #心跳检测的文件 server web1 192.168.16.2:80 cookie web1 check inter 1500 rise 3 fall 3 weight 1 #服务器定义，cookie 1表示serverid为web1，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用， #fall 3是3次失败认为服务器不可用，weight代表权重 server web2 192.168.16.3:80 cookie web2 check inter 1500 rise 3 fall 3 weight 2 #服务器定义，cookie 1表示serverid为web2，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用， #fall 3是3次失败认为服务器不可用，weight代表权重###################backend server_blog######################backend server_blog mode http #http的7层模式 balance roundrobin #负载均衡的方式，roundrobin平均方式 cookie SERVERID #允许插入serverid到cookie中，serverid后面可以定义 option httpchk GET /index.html #心跳检测的文件 server blog1 192.168.16.2:80 cookie blog1 check inter 1500 rise 3 fall 3 weight 1 #服务器定义，cookie 1表示serverid为blog1，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重 server blog2 192.168.16.3:80 cookie blog2 check inter 1500 rise 3 fall 3 weight 2 #服务器定义，cookie 1表示serverid为blog2，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重##################backend server_bbs########################backend server_bbs mode http #http的7层模式 balance roundrobin #负载均衡的方式，roundrobin平均方式 cookie SERVERID #允许插入serverid到cookie中，serverid后面可以定义 option httpchk GET /index.html #心跳检测的文件 server bbs1 192.168.16.2:80 cookie bbs1 check inter 1500 rise 3 fall 3 weight 1 #服务器定义，cookie 1表示serverid为bbs1，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重 server bbs2 192.168.16.3:80 cookie bbs2 check inter 1500 rise 3 fall 3 weight 2 #服务器定义，cookie 1表示serverid为bbs2，check inter 1500是检测心跳频率rise 3是3次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"Linux初始化init系统：Sysvinit、Upstart和Systemd","date":"2018-09-22T07:04:38.000Z","path":"posts/Linux初始化init系统/","text":"init系统介绍Linux操作系统的启动首先从BIOS开始，接下来进入bootloader，由bootloader载入内核，进行内核初始化。内核初始化的最后一步就是启动pid为1的init进程。init以守护进程方式存在，是系统的第一个进程,，是所有其他进程的祖先。 Init系统能够定义、管理和控制 init进程的行为。它负责组织和运行许多独立的或相关的始化工作(因此被称为init系统)，从而让计算机系统进入某种用户预订的运行模式。 Linux初始化init系统包括：Sysvinit、Upstart和Systemd，它们在Ubuntu系统下的演化如下： Ubuntu 6.10及以前版本使用Sysvinit。 Ubuntu 14.10及以前版本使用Upstart，通过与Sysvinit并存。 Ubuntu 15.04开始默认使用Systemd，不能与Sysvinit或Upstart并存 Sysvinit介绍 Sysvinit就是System V风格的init系统，顾名思义，它源于System V系列UNIX。 运行级别Sysvinit用术语runlevel来定义”预订的运行模式”，默认的运行模式定义在/etc/inittab文件的initdefault项。如果没有默认的运行模式，那么用户将进入系统控制台，手动决定进入何种运行模式。 Sysvinit中运行模式描述了系统各种预订的运行模式。通常会有8种运行模式，即运行模式0-6和S。其中0表示关机，1表示单用户模式，3为命令行模式，5为GUI模式，6表示重启，1和S等往往用于系统故障之后的排错和恢复。可以看出每一种运行模式所作的初始化工作是不一样的。 Sysvinit执行顺序 /etc/rc.d/rc.sysinit /etc/rc.d/rc 和/etc/rc.d/rcX.d/ (X 代表运行级别 0-6) /etc/rc.d/rc.local X Display Manager（可选） 首先，运行rc.sysinit以便执行一些重要的系统初始化任务。 然后，Sysvinit开始运行/etc/rc.d/rc脚本。根据不同的runlevel，rc脚本将执行/etc/rc.d/rcX.d(X就是runlevel)目录下的所有启动脚本。当所有的初始化脚本执行完毕。该目录下有多个脚本，为了保证系统正常关闭，脚本是要按照顺序执行的在该目录下所有以K开头的脚本都将在关闭系统时调用，字母K之后的数字定义了它们的执行顺序。 然后，Sysvinit运行/etc/rc.d/rc.local脚本。rc.local是Linux 留给用户进行个性化设置的地方。 Sysvinit优缺点Sysvinit的优点： 是概念简单，开发人员只需要编写启动和停止脚本，概念非常清楚 确定的执行顺序，脚本严格按照启动数字的大小顺序执行，一个执行完毕再执行下一个，这非常有益于错误排查 Sysvinit的缺点： 串行地执行脚本导致Sysvinit运行效率较慢 对动态设备加载等Linux新特性支持不友好 Upstart介绍开发UpStart的缘由当Linux内核进入2.6时代时，系统支持热插拔功能，一旦新外设连接到系统，内核便可以自动实时地发现它们，并初始化这些设备，进而使用它们。这为便携式设备用户提供了很大的灵活性。 Sysvinit启动时必须一次性把所有可能用到的服务都启动起来，即使该设备没有连接，因此会造成浪费，比如为了管理打印任务，系统需要启动CUPS等服务。 UpStart基于事件机制，比如U盘插入USB接口后，udev得到内核通知，发现该设备，这就是一个新的事件。UpStart在感知到该事件之后触发相应的等待任务，比如处理/etc/fstab 中存在的挂载点。采用这种事件驱动的模式，upstart 完美地解决了即插即用设备带来的新问题。 UpStart相对于Sysvinit具有如下的优势： 更快地启动系统 当新硬件被发现时动态启动服务 硬件被拔除时动态停止服务 UpStart的原理Upstart的基本概念和设计清晰明确。UpStart主要的概念是job和event。Job就是一个工作单元，用来完成一件工作，比如启动一个后台服务，或者运行一个配置命令。每个Job都等待一个或多个事件，一旦事件发生，upstart就触发该 job 完成相应的工作。 Job包括包括TaskJob，SeriveJob和AbstractJob。其中SeriveJob代表后台服务进程，一旦开始运行就成为一个后台进程，由init进程管理。 事件是个非常抽象的概念，下面我罗列出一些常见的事件，希望可以帮助您进一步了解事件的含义： 系统上电启动，init 进程会发送”start”事件 根文件系统可写时，相应 job 会发送文件系统就绪的事件 一个块设备被发现并初始化完成，发送相应的事件 某个文件系统被挂载，发送相应的事件 类似 atd 和 cron，可以在某个时间点，或者周期的时间点发送事件 另外一个 job 开始或结束时，发送相应的事件 一个磁盘文件被修改时，可以发出相应的事件 一个网络设备被发现时，可以发出相应的事件 缺省路由被添加或删除时，可以发出相应的事件 系统初始化的过程是在工作和事件的相互协作下完成的，可以大致描述如下: 系统初始化时，init 进程开始运行，init 进程自身会发出不同的事件，这些最初的事件会触发一些工作运行。每个工作运行过程中会释放不同的事件，这些事件又将触发新的工作运行。如此反复，直到整个系统正常运行起来。 UpStart是兼容SysvInit的runlevel的，通过触发执行/etc/init/rc.conf来执行/etc/rc$.d/目录下的所有脚本。 Systemd介绍Systemd提供了和Sysvinit以及LSBinitscripts兼容的特性。系统中已经存在的服务和进程无需修改。这降低了系统向systemd 迁移的成本，使得Systemd替换现有初始化系统成为可能。 Systemd的启动速度更快，提供了比UpStart更激进的并行启动能力，采用了socket/D-Bus Activation等技术启动服务，提供按需启动的能力，只有在某个服务被真正请求的时候才启动它，当该服务结束，systemd 可以关闭它，等待下次需要时再次启动它。 Systemd还提供如下等特性: 和init比起来引导过程简化了很多 Systemd支持并发引导过程从而可以更快启动 通过控制组来追踪进程，而不是PID 优化了处理引导过程和服务之间依赖的方式 支持系统快照和恢复 监控已启动的服务；也支持重启已崩溃服务 包含了systemd-login模块用于控制用户登录 支持加载和卸载组件 低内存使用痕迹以及任务调度能力 记录事件的Journald模块和记录系统日志的syslogd模块 Systemd的单元概念系统初始化需要执行的任务非常多。每一个任务都被Systemd 抽象为一个配置单元，即unit。当前单元类型如下： service：代表一个后台服务进程，比如 mysqld。这是最常用的一类。 socket：此类配置单元封装系统和互联网中的一个 套接字 。当下，systemd 支持流式、数据报和连续包的 AF_INET、AF_INET6、AF_UNIX socket 。每一个套接字配置单元都有一个相应的服务配置单元 。相应的服务在第一个”连接”进入套接字时就会启动(例如：nscd.socket 在有新连接后便启动 nscd.service)。 device：此类配置单元封装一个存在于 Linux 设备树中的设备。每一个使用 udev 规则标记的设备都将会在 systemd 中作为一个设备配置单元出现。 mount：此类配置单元封装文件系统结构层次中的一个挂载点。Systemd 将对这个挂载点进行监控和管理。比如可以在启动时自动将其挂载；可以在某些条件下自动卸载。Systemd 会将/etc/fstab 中的条目都转换为挂载点，并在开机时处理。 automount：此类配置单元封装系统结构层次中的一个自挂载点。每一个自挂载配置单元对应一个挂载配置单元 ，当该自动挂载点被访问时，systemd 执行挂载点中定义的挂载行为。 swap: 和挂载配置单元类似，交换配置单元用来管理交换分区。用户可以用交换配置单元来定义系统中的交换分区，可以让这些交换分区在启动时被激活。 target：此类配置单元为其他配置单元进行逻辑分组。它们本身实际上并不做什么，只是引用其他配置单元而已。这样便可以对配置单元做一个统一的控制。这样就可以实现大家都已经非常熟悉的运行级别概念。比如想让系统进入图形化模式，需要运行许多服务和配置命令，这些操作都由一个个的配置单元表示，将所有这些配置单元组合为一个目标(target)，就表示需要将这些配置单元全部执行一遍以便进入目标所代表的系统运行状态。 (例如：multi-user.target 相当于在传统使用 SysV 的系统中运行级别 5) timer：定时器配置单元用来定时触发用户定义的操作，这类配置单元取代了 atd、crond 等传统的定时服务。 snapshot：与 target 配置单元相似，快照是一组配置单元。它保存了系统当前的运行状态。 Systemd的Target和运行级别systemd使用目标（target）替代了运行级别的概念，提供了更大的灵活性，如您可以继承一个已有的目标，并添加其它服务，来创建自己的目标。通过target文件夹的命令也可以看出对应的runlevel： Sysvinit运行级别 Systemd目标 备注 0 poweroff.target 关闭系统 1,s rescue.target 单用户模式 2,4 multi-user.target 多用户，非图形化 3 multi-user.target 多用户，非图形化 5 graphical.target 多用户，图形化 6 reboot.target 重启 使用C/C++开发新的系统服务使用C/C++开发新的系统服务可能需要关注如下的内容： 后台服务进程代码不需要执行两次派生来实现后台精灵进程，只需要实现服务本身的主循环即可。 不要调用 setsid()，交给 systemd 处理 不再需要维护 pid 文件。 Systemd 提供了日志功能，服务进程只需要输出到 stderr 即可，无需使用 syslog。 处理信号 SIGTERM，这个信号的唯一正确作用就是停止当前服务，不要做其他的事情。 SIGHUP 信号的作用是重启服务。 需要套接字的服务，不要自己创建套接字，让 systemd 传入套接字。 使用 sd_notify()函数通知 systemd 服务自己的状态改变。一般地，当服务初始化结束，进入服务就绪状态时，可以调用它。 Unit文件的编写服务配置单元文件以.service为文件名后缀，默认时存放在/lib/systemd/system/目录下，然后链接到/etc/systemd/system/对应的目录下。下面以sshd的为例/etc/system/system/sshd.service： 123456789101112[Unit]Description=OpenSSH server daemon[Service]EnvironmentFile=/etc/sysconfig/sshd #设置环境变量ExecStartPre=/usr/sbin/sshd-keygenExecStart=/usrsbin/sshd –D $OPTIONSExecReload=/bin/kill –HUP $MAINPIDKillMode=processRestart=on-failureRestartSec=42s[Install]WantedBy=multi-user.target #系统以该形式运行时，服务方可启动 文件分为三个小节，其中[Unit]段和[Install]段是所有Unit文件通用的，用于配置服务的描述、依赖和随系统启动方式，而[Service]断则是服务类型的Unit文件（后缀为.service)特有的，用于定义服务的具体管理和操作方法。 在/etc/systemd/system 目录下还可以看到诸如*.wants 的目录，放在该目录下的配置单元文件等同于在[Unit]小节中的 wants关键字，即本单元启动时，还需要启动这些单元。比如您可以简单地把您自己写的 foo.service 文件放入 multi-user.target.wants 目录下，这样每次都会被默认启动了。 [Unit]参数 Description： 一段描述这个Unit文件的文字，通常只是简短的一句话。 Documentation：指定服务的文档，可以是一个或多个文档的URL路径。 Requires：依赖的其他Unit列表，列在其中的Unit模块会在这个服务启动的同时被启动。 Wants：与Requires相似，但只是在被配置的这个Unit启动时，触发启动列出的每个Unit模块，而不去考虑这些模块启动时候是否成功。 After：与Requires相似，但是在后面列出的所有模块启动完成以后，才会启动当前的服务。与Requires不同的是，After不会因为依赖程序在运行过程中停止运行，导致当前服务也停止。 Before：与After相反，在启动指定的任意一个模块之前，都会首先确保当前服务已经运行。 BindsTo：与Requires非常相似，但是一种更强的关联。启动这个服务时会同时启动列出的所有模块，当有模块启动失败时终止当前服务。反之，只要列出的模块全部启动以后，就会自动启动当前服务。并且，这些模块中有任意一个出现意外结束或重启，这个服务会跟着终止或重启。 PartOf：这是一个BindsTo作用的子集，仅在列出的任何模块失败或重启时，终止或重启当前服务，而不会随列出模块的启动而启动。 OnFailure：当这个模块启动失败时，就自动启动列出的每个模块。 Conflicts：与这个模块有冲突的模块，如果列出的模块中有已经在运行的，则会将已启动的冲突模块停止，并启动当前模块；反过来，冲突模块启动时会把当前模块停止。 上面的这些配置，除了Description外，其他都可以被添加多次。比如After参数，可以使用多个After参数，也可以在一行内使用空格分割，写多个依赖模块。 [install]参数 WantedBy：和前面Wants作用相似，但此处表示当前模块被依赖。 RequiredBy：和前面的Requires作用相似，但此处表示当前模块被依赖。 Also：当这个服务被enable/disable时，将自动enable/disable后面列出的每个模块。 [service]参数服务生命周期控制相关的参数 Type：服务的类型，常用的有simple（默认类型）和forking，默认的simple类型可以适用于绝大多数场景，因此一般可以忽略者这个参数的配置。对于服务进程启动后通过fork系统调用创建子进程，然后关闭应用程序本身进程的情况，则应该将Type的值设置为forking；否则Systemd将不会跟踪子进程的行为，而认为服务已经退出。 RemainAfterExit：指为true或false（也可以写yes或no），默认为false。当配置为true时，Systemd只会负责启动服务进程，之后即便服务进程退出了，Systemd也仍然会认为这个服务还在运行中。这个配置主要是提供给一些并非常驻内存，而是启动注册后立即退出，然后等待消息按需启动的特殊类型服务使用的。 ExecStart：这个参数是几乎每个“.service”文件都会有的，指定服务启动的主要命令，在每个配置文件中只能使用一次. ExecStartPre：指定在启动执行ExecStart命令前的准备工作，在同一个配置文件中可以有多个，所有命令会按照文件中书写的顺序依次被执行。 ExecStartPost：指定在启动执行ExecStart命令后的收尾工作，在同一个配置文件中也可有多个。 TimeoutSec：快速设置TimeoutStartSec和TimeoutStopSec参数成指定值。（另外，关于默认时间设定都在systemd配置文件中的DefaultTimeoutStartSec、DefaultTimeoutStopSec和DefaultRestartSec字段进行配置，如果这些字段缺省，DefaultTimeoutStartSec和DefaultTimeoutStopSec的默认指为90s，DefaultRestartSec默认为100ms） TimeoutStartSec：启动服务时的等待秒数，如果超出这个时间服务仍然没有执行完所有的启动命令，则Systemd会认为服务自动失败。这一配置对于使用Docker容器托管的应用十分重要。由于Docker第一次运行时可能会需要从网络上下载服务的镜像文件，因此造成比较严重的延时，容易被Systemd误判断为启动失败而杀死。通常，对于这种服务，需要将TimeoutStartSec设置为0，关闭超时检测。 ExecStop：停止服务所需要执行的主要命令，在每个配置文件中只能够有一个。 ExecStopPost：指定在ExecStop命令执行后的收尾工作，在同一配置文件中可以有多个。 TimeoutStopSec：停止服务时的等待秒数，如果超过这个时间服务仍然没有停止，Systemd会使用SIGKILL信号强行干掉服务进程。 Restart：这个值用于指定在什么情况下需要重启服务进程。常用的值有：no、no-success、on-failure、on-abnormal、on-abort和always。默认值为no，即不会自动重启服务。这些不同的值分别表示在哪些情况下，服务会重新启动。 RestartSec：如果服务需要被重启，这个参数的值为服务被重启前的等待秒数。默认为100ms。 ExecReload：重新加载服务所需执行的主要命令。 服务上下文配置相关的参数 Environment：为服务添加环境变量，格式直接为Environment=“foo=bar”（看了一下Systemd的手册，这个参数所接受的格式有些奇葩，建议是直接“foo=bar”，取的时候使用${foo}进行获取） EnvironmentFile：指定加载一个包含服务所需的环境变量列表的文件，文件中的每一行都是一个环境变量的定义。顺便提一下，建议使用的时候将=换成=-，如EnvironmentFile=-/etc/my.env，和=的区别是，使用=-时，假如/etc/my.env文件不在也不会报错。 Nice：服务的进程优先级，指越小优先级越高，默认为0，。其中-20为最高优先级，19为最低优先级。 WorkingDirectory：指定当前服务的工作目录。 RootDirectory：指定当前服务进程的根目录（/目录）。如果配置了这个参数，服务将无法访问指定目录外的任何文件。 User：指定运行服务的用户，会影响服务对本地文件系统的访问权限。 Group：指定运行服务的用户组，会影响服务对本地文件系统的访问权限。 MountFlags：这个值其实是服务的Mount Namespace的配置，会影响服务进程上下文中挂载点的信息，即服务是否会继承主机上已有的挂载点，以及如果服务运行时执行了挂载或卸载设备的操作，是否会真实地在主机上产生效果。可选值为shared、slave和private，具体作用如下表所示： LimitCPU/LimitSTACK/LimitNOFILE/LimitNPROC等：限定服务可用的系统资源量，CPU、程序堆栈、文件句柄数量、子进程数量等 Systemd命令行工具的使用systemd 的主要命令行工具是systemctl，可以替换service、chkconfig以及telinit命令的使用。 Systemd命令和sysvinit命令的对照表 Sysvinit命令 Systemd命令 备注 service foo start systemctl start foo.service 用来启动一个服务 (并不会重启现有的) service foo stop systemctl stop foo.service 用来停止一个服务 (并不会重启现有的) service foo restart systemctl restart foo.service 用来停止并启动一个服务 service foo reload systemctl reload foo.service 当支持时，重新装载配置文件而不中断等待操作 service foo condrestart systemctl condrestart foo.service 如果服务正在运行那么重启它 service foo status systemctl status foo.service 汇报服务是否正在运行 ls /etc/rc.d/init.d/ systemctl list-unit-files –type=service 用来列出可以启动或停止的服务列表 chkconfig foo on systemctl enable foo.service 在下次启动时或满足其他触发条件时设置服务为启用 chkconfig foo off systemctl disable foo.service 在下次启动时或满足其他触发条件时设置服务为禁用 chkconfig foo systemctl is-enabled foo.service 用来检查一个服务在当前环境下被配置为启用还是禁用 chkconfig –list systemctl list-unit-files –type=service 输出在各个运行级别下服务的启用和禁用情况 chkconfig foo –list ls /etc/systemd/system/*.wants/foo.service 用来列出该服务在哪些运行级别下启用和禁用 chkconfig foo –add systemctl daemon-reload 当您创建新服务文件或者变更设置时使用 telinit 3 systemctl isolate multi-user.target (OR systemctl isolate runlevel3.target OR telinit 3) 改变至多用户运行级别 systemd电源管理命令 命令 操作 systemctl reboot 重启机器 systemctl poweroff 关机 systemctl suspend 待机 systemctl hibernate 休眠 systemctl hybrid-sleep 混合休眠模式（同时休眠到硬盘并待机）","tags":[{"name":"Linux","slug":"Linux","permalink":"http://ruanxinyu.github.io/tags/Linux/"}]},{"title":"Ubuntu下KeepAlived的安装与配置","date":"2018-09-18T12:42:46.000Z","path":"posts/Ubuntu下KeepAlived的安装与配置/","text":"KeepAlived介绍Keepalived是一个基于VRRP协议来实现的服务高可用方案，可以利用其来避免IP单点故障，一般与其它负载均衡技术（如lvs、haproxy、nginx）一起工作来达到集群的高可用。 健康检查和失败切换是keepalived的两大核心功能。 keepalived的健康检查支持tcp三次握手、icmp请求、http请求、udp和echo请求等方式对负载均衡器后面的实际的服务器)进行保活，具体采用哪种检查方式可以根据自己的业务需要进行选择； 失败切换主要是应用于配置了主备模式的负载均衡器， 由VRRP(虚拟路由冗余协议）协议实现，对外提供一个VIP（虚拟IP），VIP在其中master机器上，当该机器出现故障时，VIP会自动漂移到slave的机器上，从而保证对外的功能是正常的。如果mastr机器功能正常之后，会自动加入到服务器集群中，无需人工干预，只需要人工做修复故障的服务器。 VRRP协议介绍VRRP（虚拟路由协议，virtual redundant routing protocol)是为消除网络设备单点故障而设计的主备模式的协议，使得在发生故障时，可以在不影响内外数据通信，不修改内部网络的网络参数的情况下切换设备。 VRRP协议通过配置虚拟路由ID(VRID)来将两台或多台设备虚拟成一个虚拟设备，对外提供一个或多个虚拟IP(VIP)和虚拟的MAC地址（VMC），通过该VIP和VMC对外提供服务，可以保证在设备切换时网络参数不变。所以当VIP在哪一台设备上，则该设备为master节点对外提供服务，其他的节点为backup节点不实际对外提供服务。 VRRP协议通过心跳算法自动选举哪个节点为master节点，默认使用多播数据来传输VRRP数据。通过配置文件可以指定每个设备的优先级，所以在初始状态时，优先级最大的为master节点。VRRP运行时只有MASTER路由器定时发送VRRP通告信息，表示master工作正常，backup只接收VRRP数据，不发送数据，如果一定时间内没有接收到master的通告信息，各backup将宣告自己成为master，发送通告信息，重新进行master选举状态。 KeepAlived的安装该教程使用的Ubuntu版本是18.04.1版本，Ubuntu的安装教程参考VirtualBox安装Ubuntu教程。KeepAlived可以直接通过apt-get安装，也可以通过源码编译安装。 apt-get安装Ubuntu下执行sudo apt-get install keepalived命令即可安装。 通过which keepalived可以看到KeepAlived是安装在/usr/sbin/keepalived下。 使用sudo service keepalived start即可启动KeepAlived。 源码编译安装源码安装的脚本可以点击此处下载： keepalived_install.sh，下面对安装过程做一下说明。 首先安装编译工具和openssl，下载KeepAlived源码并解压，然后执行源码编译三件套（./configure &amp;&amp; make &amp;&amp; make install），我们安装的目录为/usr/local/keepalived： 1234567sudo apt-get install build-essential libssl-dev # 安装编译工具和openssl依赖wget http://www.keepalived.org/software/keepalived-2.0.7.tar.gz # 下载源码tar -zxvf keepalived-2.0.7.tar.gz # 解压源码cd keepalived-2.0.7/./configure --prefix=/usr/local/keepalived # 配置keepalived的安装目录make # 编译源码sudo make install # 安装到安装目录，需要使用root权限 可能遇到的问题 执行./configure时提示g++ is not found 源码安装需要安装编译器将源码转换为二进制可执行文件，因此执行sudo apt-get install build-essential安装编译器即可 执行./configure时提示OpenSSL is not properly installed on your system 你的系统没有安装openssl，执行sudo apt-get install libssl-dev即可 守护进程和开机启动由于Ubunt 18.04.1默认使用Systemd作为init程序，因此设置守护进程也采用该方式，了解详细请参考Linux初始化init系统：Sysvinit、Upstart和Systemd 首先，创建相关文件的链接： 1234sudo mkdir -p /etc/keepalivedsudo ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin/sudo ln -s /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.confsudo ln -s /usr/local/keepalived/etc/sysconfig/keepalived /etc/default/keepalived 我们还是采用systemd的方式添加到系统服务，执行如下命令： 123456789101112131415161718192021222324(cat &lt;&lt;EOF[Unit]Description=Keepalive Daemon (LVS and VRRP)After=syslog.target network-online.targetWants=network-online.target# Only start if there is a configuration fileConditionFileNotEmpty=/etc/keepalived/keepalived.conf[Service]Type=forkingKillMode=process# Read configuration variable file if it is presentEnvironmentFile=-/etc/default/keepalivedExecStart=/usr/sbin/keepalived $KEEPALIVED_OPTIONSExecReload=/bin/kill -HUP $MAINPID[Install]WantedBy=multi-user.targetEOF) &gt; keepalived.servicesudo cp -a keepalived.service /lib/systemd/system/keepalived.servicesudo ln -s /lib/systemd/system/keepalived.service /etc/systemd/system/multi-user.target.wants/keepalived.service 启动keepalived进程，并设置为开机启动，通过sudo systemctl status keepalived查看状态： 123sudo systemctl start keepalivedsudo systemctl status keepalivedsudo systemctl enable keepalived KeepAlive的配置keepalived.conf在keepalived的安装目录/usr/local/keepalived/etc/keepalived/samples/有很多样例配置，每一种配置对应的都是一种使用场景，后续会做详细说明，因此在此处不做过多的分析。 此处使用最简单的配置入门，假设我们以/tmp/目录下是否存在service_ok这个文件来判断服务是否可用。可参考样例/usr/local/keepalived/etc/keepalived/samples/keepalived.conf.vrrp.localcheck 12345678910111213141516171819vrrp_script chk_service_ok &#123; script \"ls /tmp/service_ok\" # 检查文件是否存在 interval 2 # 每两秒钟检查一次&#125;vrrp_instance VI_1 &#123; interface enp0s3 # 指定网卡 state MASTER # 角色，主机为MASTER，备机为BACKUP virtual_router_id 51 # 虚拟路由Id，相同的ID表示在相同的组 priority 100 # 优先级，MASTER的优先级要比BACKUP的大 virtual_ipaddress &#123; # 虚拟IP地址，即VIP 192.168.42.23/25 &#125; track_script &#123; # 设置vrrp检查脚本的名称 chk_service_ok &#125;&#125; KeepAlived的验证我们使用两台虚拟机，IP地址分别为主机vm01（192.168.42.21）和备机vm02（192.168.42.22）， VIP为192.168.42.23。安装好KeepAlived后, 编辑配置文件sudo vim /etc/keepalived/keepalived.conf 主机vm01（192.168.42.21）的配置如下： 12345678910111213141516171819vrrp_script chk_service_ok &#123; script \"ls /tmp/service_ok\" interval 2&#125;vrrp_instance VI_1 &#123; interface enp0s3 state MASTER virtual_router_id 51 priority 100 virtual_ipaddress &#123; 192.168.42.23/25 &#125; track_script &#123; chk_service_ok &#125;&#125; 备机vm02（192.168.42.22）的配置如下，相对于vm01，只修改state和priority: 12345678910111213141516171819vrrp_script chk_service_ok &#123; script \"ls /tmp/service_ok\" interval 2&#125;vrrp_instance VI_1 &#123; interface enp0s3 state BACKUP virtual_router_id 51 priority 80 virtual_ipaddress &#123; 192.168.42.23/25 &#125; track_script &#123; chk_service_ok &#125;&#125; 首先，我们在两台机器上都创建一个system_ok文件，表示机器是OK的，touch /tmp/service_ok。然后执行sudo systemctl restart keepalived重新启动两台机器的keepalived。 分别在两台机器上执行ip a查看机器的网络信息，可以发现VIP（192.168.42.23）已经在主机vm01上，我们通过ssh ruan@192.168.42.23登陆到的也是主机vm01。 我们删除主机vm01上的/tmp/service_ok文件，然后重新执行ip a，发现VIP（192.168.42.23）已经漂移到备机vm02上，此时我们通过ssh ruan@192.168.42.23登陆则是备机vm02。即当主机故障时，业务可以自动切换至备机。 我们重新创建主机vm01上的/tmp/service_ok文件，，然后重新执行ip a，发现VIP（192.168.42.23）已经重新漂移到备机vm01上，此时我们通过ssh ruan@192.168.42.23登陆重新回到主机vm01。即当主机恢复时，可以自动将该主机加入到服务器群提供服务。","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"VirtualBox安装Ubuntu教程","date":"2018-09-16T11:59:38.000Z","path":"posts/VirtualBox安装Ubuntu教程/","text":"基础准备工作本教程使用的VirtualBox版本为5.2.18，Ubuntu版本为server 18.04.1。 首先，下载Ubuntu Server镜像，本文以ubuntu-18.04.1为例，可以从华为开源镜像站提供加速下载，地址为： http://mirrors.huaweicloud.com/repository/ubuntu-releases/18.04.1/ubuntu-18.04.1-live-server-amd64.iso 下载并安装VirtualBox，下载地址为: https://download.virtualbox.org/virtualbox/5.2.18/VirtualBox-5.2.18-124319-Win.exe 创建虚拟机 打开VirtualBox，点击新建, 输入名称，比如叫做UbuntuTemplate，之所以叫这个名称是因为如果后续需要多个Ubuntu虚拟机的话，可以直接复制该虚拟机，这样每次都可以有一个全新的虚拟机。操作系统版本选择Ubuntu(64bit), 点击下一步，内存选择512M或者1024M都可以，因为我们下载的镜像是没有桌面的，因此对内存要求没有那么大。 选择现在创建虚拟磁盘，当然，如果也可以使用已经存在的磁盘，下一步，磁盘类型我更愿意用VMDK(虚拟机磁盘)，因此该磁盘VMWare也是可以使用的，磁盘大小选择动态分配大小。 此处有两个地方需要注意一下： 选择磁盘的保存位置默认为虚拟机名称，这个时候是保存在用户目录下的，也就是C盘，因此最好是自己选择路径保存到其他目录，以免占用过多的C盘空间。 此处设置的其实是磁盘的最大大小，默认的10G肯定是太小了，可以直接改成100G, 这个是最大值，不是立即分配这么大的磁盘空间。 设置虚拟机设置粘贴板 导入操作系统镜像从设置的系统标签页中可以看出系统的启动顺序是“软驱”-&gt;”光驱”-&gt;”硬盘”，因此只要在光驱中导入刚刚下载的操作系统镜像，启动的虚拟机的时候就会开始安装操作系统。 设置虚拟机网络虚拟机的网络连接方式有很多中，因为涉及到很多网络知识，总结起来就是一张表，如下所示： 因为在做实验的情况下，默认都是希望虚拟机能够访问外网，虚拟机与虚拟机之间，虚拟机与宿主机之间也是可以相互访问的，因此选择桥接模式，网卡选择你当前正在使用的网卡，这样你的虚拟机就相当于是另外与宿主机相同的电脑。 安装Ubuntu 通过方向键移动，回车确认，如果发现鼠标在虚拟机捕获出不来了，可以按键盘右边的CTRL键 启动虚拟机，语言选择英文，然后选择Install Ubuntu。 如果你的宿主机连接的是路由器，那么一般都是通过DHCP自动分配的IP地址，这样的话虚拟机也能通过DHCP自动获取IP地址，从下图中可以看出对应的IP。 如果你的宿主机能够正常上网就不需要配置proxy，直接回车确认下一步就可以。 配置Ubuntu的源，也就是安装软件的默认下载地址，为了提高下载速度，我一般使用华为开源镜像站的源：https://mirrors.huaweicloud.com/ubuntu/ 我们可以手动对磁盘进行分区，但是这个需要对Linux很熟悉，因此此处我们直接选择Use An Entre Disk，让操作系统自动分区。 接下来会让你确认磁盘和分区信息，我们继续就可以。 然后输入你的主机名和密码等信息，ssh identify是用于免密码登陆linux的，一般不需要设置。 接下来会让你安装一些默认的应用程序，也可以什么都不装，保持一个最纯净的系统。 等待安装完毕，就可以开开心心重启了， 重启的过程中VirtualBox会提示你是否将光驱中的镜像移除掉，直接回车就可以移除就剋有了，这样就可以直接从磁盘启动你刚刚安装的系统，否则还是会从光驱中启动。 启动后输入用户名密码，输入ip a命令可以看到虚拟机的IP地址: 由于Ubuntu自带的控制台使用不是很方便，因此可以直接通过xshell连接该虚拟机 VirtualBox的使用说明鼠标捕获如果发现鼠标在虚拟机捕获出不来了，可以按键盘右边的CTRL键 保存快照如下所示，一般第一次安装的时候都做一次快照，因此这样即使后续做了破坏性的操作也可以快速还原。 快速保存并恢复关闭虚拟机时可以选择快速休眠，下次启动的时候就可以快速从将虚拟机从当前状态恢复。 复制虚拟机在做实验的时候需要使用多个虚拟机，不用重新安装，直接复制虚拟机即可，在对应的虚拟机上右键就可以，需要在关机的状态下才能复制。但是在复制虚拟机之后最后刷新一下网卡的MAC地址，否则可能会出现相同MAC地址的情况。","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"每天学习一个Linux命令（3）：echo命令","date":"2018-05-02T11:20:58.000Z","path":"posts/每天学习一个Linux命令（3）：echo命令/","text":"echo命令用于输出字符串，可以通过参数和转义等来控制输出格式。 语法1echo [-neE] [arg ...] 参数 -n 打印不添加换行符 -e 使能转义字符 转义字符 \\b 退格键，即删除一个字符 \\c 抑制后续的输出 \\n 换行 \\t tab键 \\\\ 斜杠 使用小技巧 echo是shell的内部命令，因此查看帮助需要使用help echo echo后的字符串如果使用单引号括起来，则转义和变量都失效(重要) 通过-e参数和\\c转义可以控制换行的输出 常用范例范例1： 显示普通字符串命令： echo &quot;this is a text&quot; # 也可以不加引号输出：1this is a text 范例2： 显示转义字符命令： echo &quot;\\&quot;this is a text\\&quot;&quot;输出：1&quot;this is a text&quot; 范例3： 显示变量命令：12text=\"ffff\"echo \"this is a $&#123;text&#125;\" 输出：1this is a ffff 范例4： 输出换行命令：12echo -e \"this \\n\"echo \"is a text\" 输出：123this is a text 范例5： 不输出换行命令：12echo -e \"this \\c\"echo \"is a text\" 输出：1this is a text （注：相比于上面的命令，少了两个换行） 范例6： 禁止显示转义和变量（使用单引号）命令： echo &#39;$name\\&quot;&#39; # 这个很重要输出：1$name\\&quot; 范例7： 显示命令执行的结果命令：12echo `date`echo $(date) 输出：12Tue May 1 21:16:57 CST 2018Tue May 1 21:16:57 CST 2018","tags":[{"name":"Linux","slug":"Linux","permalink":"http://ruanxinyu.github.io/tags/Linux/"}]},{"title":"每天学习一个Linux命令（2）：cd命令","date":"2018-05-01T10:00:58.000Z","path":"posts/每天学习一个Linux命令（2）：cd命令/","text":"cd命令用于切换至目标目录，以/开头的则为绝对路径，否则为相对路径。 语法1cd [dir] 使用小技巧 切换至用户所示在的目录可以使用cd ~ 或者 cd(不带参数) &quot;.&quot; 则是表示目前所在的目录，&quot;..&quot; 则表示目前目录位置的上一层目录 通过pwd命令可以打印当前所在的目录 cd -表示切换至上一次所在的目录 常用范例范例1： 切换至根目录下的var目录下命令： cd /var(绝对路径) 范例2： 切换至当前目录下的var目录下命令： cd var(相对目录) 范例3： 切换至上两级的目录命令： cd ../../ 范例4： 切换至包含空格的目录命令： cd &#39;aa aa&#39;或者cd aa\\ aa 范例5： 切换至当前用户的home目录命令： cd ~或者cd 范例6： 打印当前所在的目录命令： pwd 范例7： 切换到上一次所在的目录命令： cd -","tags":[{"name":"Linux","slug":"Linux","permalink":"http://ruanxinyu.github.io/tags/Linux/"}]},{"title":"每天学习一个Linux命令（1）：ls命令","date":"2018-05-01T08:18:02.000Z","path":"posts/每天学习一个Linux命令（1）：ls命令/","text":"ls命令是linux下最常用的命令。ls命令就是list的缩写，用于显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录)。 语法1ls [OPTION]... [FILE]... 参数 -a 显示所有文件及目录，包括以.开头的隐藏文件 -A 同 -a ，但不列出 “.” (目前目录) 及 “..” (父目录) -l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出 -h human-readable，默认-l参数显示出来的文件大小是字节大小，-h参数可以按照KB/MB/GB来显示 -r reverse，将文件以相反次序显示(原定依英文字母次序) -t 将文件依建立时间之先后次序列出 -F 在列出的文件名称后加一符号；例如可执行档则加 “*”, 目录则加 “/“ -R recursive，若目录下有文件，则以下之文件亦皆依序列出 使用小技巧 一般Linux操作系统都会存在一个ll的命令，相当于ls -l --color=auto ls命令使支持*通配符的 常用范例范例1： 列出/var目录下的文件命令： ls /var结果： 范例2： 列出目前工作目录下所有名称是s开头的文件，越新的排越后面命令： ls -ltr s*结果： 范例3： 将/bin目录以下所有目录及文件详细资料列出命令： ls -lR /bin","tags":[{"name":"Linux","slug":"Linux","permalink":"http://ruanxinyu.github.io/tags/Linux/"}]},{"title":"如何使用GitHubPages搭建个人博客","date":"2018-04-30T12:07:11.000Z","path":"posts/如何使用GitHubPages搭建个人博客/","text":"我对个人博客的要求我对个人博客有如下几点要求，因此最终选定通过Hexo+GitHub Pages来搭建。 存在独立域名，别人能通过互联网访问 通过Git进行管理，支持MarkDown语法 不需要自己购买主机维护环境 支持评论分享等功能 配置GitHub Pages 前提： 您需要有一个GitHub的账号，请将下文中的ruanxinyu替换为您的用户名。 点击此处，创建一个仓库， 一般GitHub Pages对应的仓库名称规则为： 用户名.github.io， 如下图所示： 现在仓库有了，但是在推送内容之前还需要设置GitHub的SSH秘钥，通过如下命令生成并查看SSH秘钥，如果需要输入，一路回车就即可： 12ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; cat /c/Users/you/.ssh/id_rsa.pub 进入到GitHub的Setting页面，添加SSH秘钥，如下图所示： 下面，我们往仓库中推送一个index.html页面来充当我们的博客，可以参考如下命令：（Windows下可以使用git bash终端运行如下命令） 123456git clone git@github.com:RuanXinyu/ruanxinyu.github.io.gitcd ruanxinyu.github.ioecho \"Hello World\" &gt; index.htmlgit add --allgit commit -m \"Initial commit\"git push -u origin master 此时你的博客已经产生，网址为：https://ruanxinyu.github.io/, 点击即可访问: 安装并体验Hexo GitHub Pages相当于一个静态网站，您需要将您的博客全部转换为html页面才可以，当然，这个繁琐的过程不需要我们自己去完成，当前有两个框架可以做这个事情：Jekyll和Hexo，下面我就介绍一下如何通过Hexo快速的发表自己的文章。 Hexo是一个NodeJS实现的博客框架，官方文档地址为： https://hexo.io/zh-cn/docs/, 文档存在中文哦，给力吧！下面说一下使用过程： 执行npm install -g hexo-cli命令安装Hexo（在安装Hexo之前，请您自行安装NodeJS和NPM） 执行hexo init xxx创建一个博客 执行hexo generate渲染MarkDown博文，渲染出来的结果在public目录下 执行npm install hexo-server --save安装server工具，然后执行hexo server，访问http://localhost:4000/网址可在本地访问你的博客，该方式主要用于调试。 执行hexo new xxx创建一篇博文，博文的文件存放在source\\_posts目录下，编辑文档内容，hexo server会自动检测文章的变化并运行generate命令，因此刷新本地网址即可看到你更新的内容。 在将博文推送到GitHub Pages之前，执行npm install hexo-deployer-git --save安装部署工具，然后将根目录下的_config.yml文件中的如下内容更改为您的GitHub Pages的仓库地址，注意是git@开头的地址，否则在使用hexo deploy会报错 1234deploy: type: git repo: git@github.com:RuanXinyu/ruanxinyu.github.com.git branch: master 执行hexo deploy， Hexo将渲染后的页面放到.deploy_git目录，本地提交后，自动将您的博文推送到GitHub Pages所对应的仓库 此时，访问您的GitHubPages就可以看到你更新的文章内容。 切换到Indigo主题Hexo默认使用的是landscape主题，如果不符合自己的审美，可以在https://hexo.io/themes/查找自己喜欢的主题。我比较喜欢indigo主题，该主题有平铺和卡片两种显示方式，卡片模式的代码是在card分支下，下面以此主题为例。 克隆该主题的代码仓库，如下： 1git clone -b card https://github.com/yscoder/hexo-theme-indigo.git themes/indigo 安装Indigo主题依赖的插件 1234npm install hexo-renderer-less --savenpm install hexo-generator-feed --savenpm install hexo-generator-json-content --savenpm install hexo-helper-qrcode --save 修改顶层配置文件_config.yml中的theme: landscape为theme: indigo，刷新页面即可看到新的主题。 配置Hexo和Indigo主题Hexo的配置文件为_config.yml，Indigo主题的配置文件在themes/indigo/_config.yml。 Hexo的配置说明文档地址为： https://hexo.io/zh-cn/docs/configuration.htmlIndigo主题的配置说明文档地址为： https://github.com/yscoder/hexo-theme-indigo/wiki/%E9%85%8D%E7%BD%AE 官方文档已经描述很清楚，当然，最简单的方式是基于别人的进行修改，因此在此我贡献出我的配置，然后对几个点做一下说明。 Hexo配置文件样例 language: zh-CN: 语言的种类可以参考themes/indigo/languages目录下的文件 post_asset_folder: true: 在创建博文的时候自动生成对应的文件夹，以存放该博文对应的图片 配置文件末尾的feed和jsonContent两部分分别是hexo-generator-feed和hexo-generator-json-content两个插件的配置，该部分说明在Indigo的说明文章中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: RuanXinYu's Blogsubtitle: 路漫漫其修远兮，吾将上下而求索description: 阮新宇的成长记录keywords: Ruandyauthor: 阮新宇email: 1096421257@qq.comurl: http://ruanxinyu.github.io/language: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'root: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: truerelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: true # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 20 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 20pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: indigo# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:RuanXinyu/ruanxinyu.github.com.git branch: masterfeed: type: atom path: atom.xml limit: 0jsonContent: meta: false pages: false posts: title: true date: true path: true text: true raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true Indigo配置文件样例 该主题对应的图片在themes/indigo/source/img，请自行进行替换 样例内容配置了百度统计功能，下文有详细描述 样例内容配置了gitment的评论功能，下文有详细描述 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162# hexo-theme-indigo# https://github.com/yscoder/hexo-theme-indigo# 添加新菜单项遵循以下规则# menu:# link: fontawesome图标，省略前缀，本主题前缀为 icon-，必须# text: About 菜单显示的文字，如果省略即默认与图标一致，首字母会转大写# url: /about 链接，绝对或相对路径，必须。# target: _blank 是否跳出，省略则在当前页面打开menu: home: text: 主页 url: / archives: text: 归档 url: /archives tags: text: 标签 url: /tags th-list: text: 分类 url: /categories github: url: https://github.com/RuanXinyu target: _blank# 你的头像urlavatar: /img/avatar.png# avatar linkavatar_link: /# 头像背景图brand: /img/brand.jpg# faviconfavicon: /favicon.ico# emailemail: 1096421257@qq.com# 设置 Android L Chrome 浏览器状态栏颜色color: '#3F51B5'# 页面标题tags_title: 标签archives_title: 归档categories_title: 分类# 文章截断excerpt_render: falseexcerpt_length: 200excerpt_link: 阅读全文...mathjax: falsearchive_yearly: true# 是否显示文章最后更新时间show_last_updated: true# 是否开启分享share: true# 是否开启打赏，关闭 reward: falsereward: title: 谢谢您的打赏 wechat: /img/wechat.png #微信，关闭设为 false alipay: /img/alipay.jpg #支付宝，关闭设为 false# 是否开启搜索search: true# 是否大屏幕下文章页隐藏导航hideMenu: false# 是否开启toc# toc: falsetoc: list_number: true # 是否显示数字排序# 文章页留言内容，hexo中所有变量及辅助函数等均可调用，具体请查阅 hexo.iopostMessage: 原始链接：&lt;a href=\"&lt;%- url_for(page.path).replace(/index\\.html$/, '') %&gt;\" target=\"_blank\" rel=\"external\"&gt;&lt;%- page.permalink.replace(/index\\.html$/, '') %&gt;&lt;/a&gt;# 站长统计，如要开启，输入CNZZ站点id，如 cnzz: 1255152447cnzz: false# 百度统计，如要开启，改为你的 keybaidu_tongji: b4c4998e548a16b827d4ffe9dbe2b47b# 腾讯分析，如要开启，输入站点idtajs: false# googlegoogle_analytics: falsegoogle_site_verification: false# sogou站长验证 http://zhanzhang.sogou.com/sogou_site_verification: false# lessless: compress: true paths: - source/css/style.less# 以下评论插件开启一个即可# 是否开启 disqusdisqus_shortname: false# 是否开启友言评论, 填写友言用户iduyan_uid: false# 是否使用 gitment，https://github.com/imsun/gitment#gitment: falsegitment: owner: RuanXinyu repo: ruanxinyu.github.com client_id: 2a6e23cf2e39e54ef316 client_secret: f237d3eb9fc94607a0454f894b143efe72eb8aca# Valine Comment system. https://valine.js.orgvaline: enable: false # 如果你想使用valine，请将值设置为 true appId: # your leancloud appId appKey: # your leancloud appKey notify: false # Mail notify verify: false # Verify code avatar: mm # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide placeholder: Just go go # Comment Box placeholder guest_info: nick,mail,link # Comment header info pageSize: 10 # comment list page size# 是否开启Hyper Comments，填写id则启用，false则禁用。http://hypercomments.com# Hyper Comments support. Write your id here, or false to disablehyper_id: false# 规范网址# 让搜索引擎重定向你的不同域名、不同子域、同域不同目录的站点到你期望的路径# https://support.google.com/webmasters/answer/139066# 假设配置为 canonical: http://imys.net，那么从搜索引擎中 www.imys.net 进入会重定向到 imys.netcanonical: false# 版权起始年份since_year: 2015# 用户页面中作者相关的描述性文字，如不需要设为 falseabout: 用户页面中作者相关的描述性文字，如不需要设为 false# “不蒜子”访问量统计，详见 http://ibruce.info/2015/04/04/busuanzi/visit_counter: site_uv: 站点总访客数： site_pv: 站点总访问量：# 动态定义titletitle_change: normal: 欢迎回来！ leave: 您还会回来吗？# 设置为 true 发布后将使用 unpkg cdn 最新的主题样式# 如果想让你的自定义样式生效，把此项设为 falsecdn: true# 设置为 true 将使用 lightbox render 图片lightbox: true# icp备案号 ICP_license: 京ICP备1234556号-1ICP_license: false 配置百度统计 百度统计是可以免费试用的，进入到百度统计注册账号，然后进入到管理页面添加你的网址，如下图所示： 添加完成之后，你就可以看到你的Key，如下图所示： 将你的key值添加到indigo主题的配置文件中即可，如下所示： 12# 百度统计，如要开启，改为你的 keybaidu_tongji: b4c4998e548a16b827d4ffe9dbe2b47b 访问百度统计查看你的网站访问情况等数据。 配置评论功能 友言评论功能已经关闭，因此采用的是gitment插件，该插件是依托于GitHub的Issue的功能的。采用npm install --save gitment命令安装gitment。 点击此处注册OAuth Application。其他内容可以随意填写，但要确保填入正确的 callback URL（一般是评论页面对应的域名，比如： https://ruanxinyu.github.io ）。 你会得到一个client ID和一个client secret，将其配置到indigo的配置文件中： 1234567# 是否使用 gitment，https://github.com/imsun/gitment#gitment: falsegitment: owner: RuanXinyu repo: ruanxinyu.github.com client_id: 2a6e23cf2e29e54ef316 client_secret: f237d3eb9fc94607a0354f894b143efe52eb8aca 页面发布后，你需要访问页面并使用你的GitHub账号登录（请确保你的账号是第二步所填repo的owner），点击初始化按钮，之后其他用户即可在该页面发表评论。 如果初始化时出现Error：validation failed，则说明你的网址超过50个字符，这是由GitHub的Issue限制的，此时可以修改themes\\indigo\\layout\\_partial\\plugins\\gitment.ejs文件的如下内容，以时间为ID： 123456789var gitment = new Gitment(&#123; id: '&lt;%- page.date %&gt;', owner: '&lt;%- theme.gitment.owner %&gt;', repo: '&lt;%- theme.gitment.repo %&gt;', oauth: &#123; client_id: '&lt;%- theme.gitment.client_id %&gt;', client_secret: '&lt;%- theme.gitment.client_secret %&gt;', &#125;,&#125;) 现在在你的博文下就可以进行评论了： 在你所指定的GitHub仓库中的Issue中也会有你的评论信息： 如果出现其他问题，可以参考：https://imsun.net/posts/gitment-introduction/和https://www.jianshu.com/p/57afa4844aaa 使用个人独立域名经过上述的配置，我们的博客已经能够在公网访问，但是如果您还想需要自己的域名，而不是以github.io结尾的，比如我的域名为：blog.ruanxinyu.cn，那么您可以按照下面的说明进行配置。 配置域名解析DNS首先您需要购买自己的域名，比如通过阿里云进行购买https://wanwang.aliyun.com/?spm=5176.8142029.388261.275.a7236d3earZNnp，该过程比较繁琐，需要认证。 域名认证通过之后，需要在添在云解析DNS中加一项CNAME将你的独立域名指向你的GitHub Pages网址，如下图所示， 其中ruanxinyu.cn是我购买的域名；blog是我为我的博客分配的二级域名，二级域名是自己随意指定的；ruanxinyu.github.io是我的GitHub Pages地址。 配置GitHub仓库进入到你的GitHub Pages所在的代码仓库的配置中，将您的域名配置进去： 到此，您就可以通过您的独立域名访问您的博客内容，比如我的：https://blog.ruanxinyu.cn 还存在一个小问题，每次你通过hexo deploy -g将你的博客推送到你的GitHubPages的时候，域名配置就丢失了，为了解决此问题，我们可以在我的Hexo工程添加一个source/CNAME文件，在该文件中写入你的独立域名，比如blog.ruanxinyu.cn，这样每次推送，都会自动给您设置域名。 通过Git的子模块功能管理主题为什么要用Git的子模块功能呢？ 我们的博客代码是存在我们自己仓库中的，而主题是从别人的仓库中拉取的，并且我们会修改主题中的配置文件。如果我们将主题的内容全部存到我们的仓库中，那么如果主题的作者更新了内容，我们想同步下来就会很费劲。而Git的子模块功能就是为了解决这个问题的，允许你将一个Git仓库当作另外一个Git仓库的子目录，允许你克隆另外一个仓库到你的项目中并且保持你的提交相对独立。 在华为DevCloud上建立私有代码仓因为敏感信息问题，我不想将hexo工程源码放和主题的源码放在gitHub上，因此我在华为软件开发云上建立了两个私有仓库: 一个用于存放我的hexo工程源码，地址为：1git@codehub.devcloud.huaweicloud.com:55d03e8e8ec445bfb3fffbc66b1001dd/Blog.git 一个用于存放我修改后的indigo主题，该仓库是从indigo的官方仓库导入进来的, 如下图所示, 地址为：1git@codehub.devcloud.huaweicloud.com:55d03e8e8ec445bfb3fffbc66b1001dd/hexo-theme-indigo.git 如何添加Git的子模块功能在第一次使用的时候，需要先添加子模块功能：1git submodule add -b card git@codehub.devcloud.huaweicloud.com:55d03e8e8ec445bfb3fffbc66b1001dd/hexo-theme-indigo.git themes/indigo 此时，会在你的代码目录下生成.gitmodules文件，该文件记录你的子模块信息：1234[submodule &quot;themes/indigo&quot;]truepath = themes/indigotrueurl = git@codehub.devcloud.huaweicloud.com:55d03e8e8ec445bfb3fffbc66b1001dd/hexo-theme-indigo.gittruebranch = card 然后执行git submodule init和git submodule update命令将远端的代码同步下来。 如何修改indigo主题的内容我们根据自己的需要修改主题文件夹中的文件，然后推送至我们的私有仓库即可，可以参考如下命令：1234cd themes/indigogit add .git commit -m '修改配置信息'git push origin card 如何同步indigo主题官方仓库的更新首先，我们将我们的仓库与官方的仓库进行一下关联，如下所示：1git remote add office -t card https://github.com/yscoder/hexo-theme-indigo.git 之后通过git pull office即可将官方的仓库合并到本地。 如何修改Hexo工程代码的内容Hexo工程就跟普通仓库一样维护即可，与子模块是相互独立的，当前两个仓库分开维护即可。Hexo工程代码并不会管理indigo主题的文件，而只是维护一个子模块的commit id。 克隆已经添加子模块功能的hexo工程使用子模块之后，克隆Hexo工程代码可以加上--recursive参数，将子模组的内容一起克隆下来，如果没有加该参数，则需要手动执行一下git submodule update：1git clone --recursive git@codehub.devcloud.huaweicloud.com:55d03e8e8ec445bfb3fffbc66b1001dd/Blog.git 你可能会遇到的坑 执行hexo deploy时报error deployer not found:github错误 您没有安装安装hexo-deployer-git造成的，通过 npm install hexo-deployer-git --save进行安装 执行hexo deploy时报Permission denied (publickey)错误 您的Github没有配置你的SSH key，配置方法参照上文的“配置GitHub Pages”章节 执行hexo deploy时报fatal: could not read Username for &#39;https://github.com&#39;: Invalid argument错误 在GitHub上设置SSH Key，同时将配置文件deploy配置下的git地址改为git@开头的ssh地址，如下所示： 1234deploy: type: git repo: git@github.com:RuanXinyu/ruanxinyu.github.com.git branch: master 百度统计没有数据 百度统计在初次添加后会有一定的延迟，可以手动检查是否添加成功，如下所示: gitment初始化评论时出现Error：validation failed 这是由于你的网址超过50个字符导致的，解决方式请参照上文“配置评论功能”中的第5条","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]},{"title":"JDK安装教程","date":"2018-04-15T06:53:32.000Z","path":"posts/JDK安装教程/","text":"学习Java，首先得安装JDK(Java Development Kit)，那么下面就说一下如何在Windows和Linux下安装并验证JDK。 JDK的下载JDK的官方下载地址为： http://www.oracle.com/technetwork/java/javase/downloads/index.html， 请根据需要下载对应操作系统的安装包。 官方下载速度比较慢，因此可以从华为开源镜像站下载，地址为：https://mirrors.huaweicloud.com/repository/toolkit/java/jdk/ Windows下安装JDK 以jdk-8u151为例，双击上一步下载下来的exe文件，默认安装即可。（备注：路径可以选择其他盘符，但是不建议路径中包含中文及特殊字符） 进入到系统环境变量的管理界面：右键计算机图标=&gt;属性=&gt;高级系统设置=&gt;环境变量 新建变量JAVA_HOME，值为：C:\\Program Files\\Java\\jdk1.8.0_151 编辑变量PATH，追加：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin; 新建变量CLASSPATH，值为：.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar Linux下安装JDK 以jdk-8u151为例，下载JDK后，将压缩包解压至特定的目录，一般解压至/usr/local目录，下载和解压命令可以参考如下命令： 123wget https://mirrors.huaweicloud.com/repository/toolkit/java/jdk/8u151-b12/jdk-8u151-linux-x64.tar.gzsudo tar -zxvf jdk-8u151-linux-x64.tar.gz -C /usr/local/sudo chown -R $(whoami):$(whoami) /usr/local/jdk1.8.0_151 经JDK的路径加入到环境变量中，在命令行中输入sudo vim /etc/profile，编辑文件，在文件末尾增加如下的内容，然后执行source /etc/profile使环境变量生效。 1234export JAVA_HOME=/usr/local/jdk1.8.0_151export JRE_HOME=/usr/local/jdk1.8.0_151/jreexport CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin JDK的验证windows打开CMD命令窗口，Linux打开终端端口，输入java -version命令，如果出现如下提示则Java安装成功。","tags":[{"name":"Java","slug":"Java","permalink":"http://ruanxinyu.github.io/tags/Java/"},{"name":"环境搭建","slug":"环境搭建","permalink":"http://ruanxinyu.github.io/tags/环境搭建/"}]}]